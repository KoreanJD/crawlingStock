{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KoreanJD/crawlingStock/blob/main/main_all_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54gK5cGIpA6F",
        "outputId": "187b1a30-9334-43a1-d053-fb51119fbf0f",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,513 kB]\n",
            "Fetched 4,635 kB in 3s (1,356 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "swig is already the newest version (4.0.2-1ubuntu1).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.10/dist-packages (2.3.8)\n",
            "\u001b[31mERROR: Invalid requirement: 'stable-base|lines3[extra]>=2.0.0a4': Expected end or semicolon (after name and no valid version specifier)\n",
            "    stable-base|lines3[extra]>=2.0.0a4\n",
            "               ^\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: stable_baselines3 in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.0.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (3.0.2)\n",
            "Requirement already satisfied: shimmy in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from shimmy) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.10/dist-packages (from shimmy) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy) (0.0.4)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ],
      "source": [
        "!apt-get update && apt-get install swig cmake\n",
        "!pip install box2d-py\n",
        "!pip install \"stable-base|lines3[extra]>=2.0.0a4\"\n",
        "!pip install stable_baselines3\n",
        "!pip install shimmy\n",
        "!pip install optuna\n",
        "pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGqti3xawqBe"
      },
      "outputs": [],
      "source": [
        "#import lib\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.utils import set_random_seed\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
        "import time\n",
        "\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from stable_baselines3.common.results_plotter import load_results, ts2xy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et2I2wqZUBw9",
        "outputId": "5fe1e922-f168-48e5-d5c1-cce90a02da3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class StockPortfolioEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Generate a stock portfolio environment for reinforcement learning.\n",
        "    basically this env super by gym of gymnasium. therfore we follow the structure of gym.env\n",
        "    data : pandas dataframe type. it is columns of ticker, index is itme series\n",
        "    \"\"\"\n",
        "    def __init__(self, data, initial_balance=10000000):\n",
        "        super(StockPortfolioEnv, self).__init__()\n",
        "        self.data = data\n",
        "        self.initial_balance = initial_balance\n",
        "        self.current_step = 0\n",
        "\n",
        "        # 포트폴리오 관련 변수\n",
        "        self.balance = initial_balance\n",
        "        self.portfolio = [0] * len(data.columns)  # 각 회사에 대한 주식 보유 수량\n",
        "        self.current_company = 0  # 현재 선택된 회사\n",
        "\n",
        "        # 행동 공간 정의: Hold, Buy, Sell, Select company\n",
        "        # self.action_space = gym.spaces.Discrete(4)\n",
        "        self.action_space = gym.spaces.MultiDiscrete([3, len(data.columns)])\n",
        "\n",
        "        # 관측 공간 정의: 모든 회사의 현재 가격 및 지표\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(len(data.columns) * 2,), dtype=np.float32)\n",
        "\n",
        "    def reset(self, seed = 42, options = None):\n",
        "        # super().reset(seed=seed)\n",
        "        self.current_step = 0\n",
        "        self.balance = self.initial_balance\n",
        "        self.portfolio = [0] * len(self.data.columns)\n",
        "        self.current_company = 0\n",
        "\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def _next_observation(self):\n",
        "        current_prices = self.data.iloc[self.current_step].values\n",
        "\n",
        "        portfolio_values = np.array(self.portfolio) * current_prices\n",
        "\n",
        "        return np.concatenate((current_prices,portfolio_values), axis=0)\n",
        "\n",
        "    def step(self, action):\n",
        "        action_type, company = action\n",
        "\n",
        "        # action_type과 company의 유효성 체크\n",
        "        if action_type not in [0, 1, 2]:\n",
        "            raise ValueError(f\"Invalid action_type: {action_type}\")\n",
        "        if company < 0 or company >= len(self.data.columns):\n",
        "            raise ValueError(f\"Invalid company index: {company}\")\n",
        "\n",
        "        current_prices = self.data.iloc[self.current_step].values\n",
        "        current_price = current_prices[company]\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= len(self.data) - 1\n",
        "\n",
        "        if action_type == 0:  # Hold\n",
        "            pass\n",
        "\n",
        "        elif action_type == 1:  # Buy\n",
        "            if self.balance >= current_price:\n",
        "                self.portfolio[company] += 1\n",
        "                self.balance -= current_price\n",
        "\n",
        "        elif action_type == 2:  # Sell\n",
        "            if self.portfolio[company] > 0:\n",
        "                self.portfolio[company] -= 1\n",
        "                self.balance += current_price\n",
        "\n",
        "\n",
        "        # 포트폴리오의 총 가치 계산\n",
        "        total_value = self.balance + np.sum(np.array(self.portfolio) * current_prices)\n",
        "        # reward = total_value - self.initial_balance\n",
        "        reward = (total_value - self.initial_balance)*10\n",
        "\n",
        "        # print(f\"Step: {self.current_step}, Action: {action}, Total Value: {total_value}, Reward: {reward}\")\n",
        "\n",
        "        obs = self._next_observation()\n",
        "\n",
        "       # 종료 플래그와 추가 정보 반환\n",
        "        terminated = bool(done)  # 자연스럽게 종료될 경우\n",
        "        truncated = False  # 에피소드가 강제 중단되는 상황을 가정하지 않음\n",
        "        info = {}\n",
        "        # obs, reward, terminated, truncated, info\n",
        "        return obs, reward, terminated, truncated, info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVgs_q6JbNG5"
      },
      "outputs": [],
      "source": [
        "# Fetch stock data from Yahoo Finance\n",
        "def fetch_stock_data(tickers, start_date='2003-01-01', end_date='2023-01-01'):\n",
        "    df_dict = {}\n",
        "    for ticker in tickers:\n",
        "        df = yf.download(ticker, start=start_date, end=end_date)\n",
        "        df_dict[ticker] = df\n",
        "    return df_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCro7geebOv2",
        "outputId": "56682d2a-3e45-4bae-f8da-f79083cbe3c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "# Define list of companies and fetch their data\n",
        "company_list = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\", \"TSLA\", \"NVDA\", \"NFLX\", \"INTC\", \"AMD\", \"BA\", \"JPM\", \"V\", \"DIS\", \"PYPL\", \"IBM\", \"ORCL\", \"KO\", \"PEP\", \"MCD\"]\n",
        "# return to dict type, each dict have dataframe type\n",
        "df_dict = fetch_stock_data(company_list)\n",
        "\n",
        "#concat dataframe of all ticker\n",
        "df = pd.DataFrame()\n",
        "for ticker in company_list:\n",
        "  df = pd.concat([df, df_dict[ticker]['Close'].transpose()])\n",
        "# basically each item should be null with total period. in that case fill na to 0\n",
        "df.fillna(0,inplace = True)\n",
        "df = df.transpose()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2PCg9lYDHSN",
        "outputId": "57a24bb8-f265-43ea-c28a-c6158f320992"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def make_env(data, rank, seed = 0):\n",
        "    def _init():\n",
        "        env = StockPortfolioEnv(data)\n",
        "        env = gym.reset(seed=seed + rank)\n",
        "        return env\n",
        "    set_random_seed(seed)\n",
        "    return _init\n",
        "\n",
        "n_envs = 4\n",
        "env = make_vec_env(make_env(df, rank=0), n_envs=n_envs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5Rc4Fd8CM_U"
      },
      "outputs": [],
      "source": [
        "PROCESSES_TO_TEST = [1, 2, 4, 8, 16]\n",
        "NUM_EXPERIMENTS = 3  # RL algorithms can often be unstable, so we run several experiments (see https://arxiv.org/abs/1709.06560)\n",
        "TRAIN_STEPS = 5000\n",
        "# Number of episodes for evaluation\n",
        "EVAL_EPS = 20\n",
        "ALGO = PPO\n",
        "# We will create one environment to evaluate the agent on\n",
        "eval_env = StockPortfolioEnv(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvLjejCmCM46",
        "outputId": "3dbbf336-b40c-46c1-dc1c-4b578021cfff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running for n_procs = 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running for n_procs = 2\n",
            "Running for n_procs = 4\n",
            "Running for n_procs = 8\n",
            "Running for n_procs = 16\n"
          ]
        }
      ],
      "source": [
        "reward_averages = []\n",
        "reward_std = []\n",
        "training_times = []\n",
        "total_procs = 0\n",
        "for n_procs in PROCESSES_TO_TEST:\n",
        "    total_procs += n_procs\n",
        "    print(f\"Running for n_procs = {n_procs}\")\n",
        "    if n_procs == 1:\n",
        "        # if there is only one process, there is no need to use multiprocessing\n",
        "        train_env = DummyVecEnv([lambda: StockPortfolioEnv(df)])\n",
        "    else:\n",
        "        # Here we use the \"fork\" method for launching the processes, more information is available in the doc\n",
        "        # This is equivalent to make_vec_env(env_id, n_envs=n_procs, vec_env_cls=SubprocVecEnv, vec_env_kwargs=dict(start_method='fork'))\n",
        "        train_env = SubprocVecEnv(\n",
        "            [make_env(df, i + total_procs) for i in range(n_procs)],\n",
        "            start_method=\"fork\",\n",
        "        )\n",
        "\n",
        "    rewards = []\n",
        "    times = []\n",
        "\n",
        "    for experiment in range(NUM_EXPERIMENTS):\n",
        "        # it is recommended to run several experiments due to variability in results\n",
        "        train_env.reset()\n",
        "        model = ALGO(\"MlpPolicy\", train_env, verbose=0)\n",
        "        start = time.time()\n",
        "        model.learn(total_timesteps=TRAIN_STEPS)\n",
        "        times.append(time.time() - start)\n",
        "        mean_reward, _ = evaluate_policy(model, eval_env, n_eval_episodes=EVAL_EPS)\n",
        "        rewards.append(mean_reward)\n",
        "    # Important: when using subprocesses, don't forget to close them\n",
        "    # otherwise, you may have memory issues when running a lot of experiments\n",
        "    train_env.close()\n",
        "    reward_averages.append(np.mean(rewards))\n",
        "    reward_std.append(np.std(rewards))\n",
        "    training_times.append(np.mean(times))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4IT3le1XqL8"
      },
      "outputs": [],
      "source": [
        "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
        "    \"\"\"\n",
        "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
        "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
        "\n",
        "    :param check_freq: (int)\n",
        "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
        "      It must contains the file created by the ``Monitor`` wrapper.\n",
        "    :param verbose: (int)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, check_freq, log_dir, verbose=1):\n",
        "        super().__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.log_dir = log_dir\n",
        "        self.save_path = os.path.join(log_dir, \"best_model2\")\n",
        "        self.best_mean_reward = -np.inf\n",
        "\n",
        "    def _init_callback(self) -> None:\n",
        "        # Create folder if needed\n",
        "        if self.save_path is not None:\n",
        "            os.makedirs(self.save_path, exist_ok=True)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "\n",
        "            # Retrieve training reward\n",
        "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
        "            if len(x) > 0:\n",
        "                # Mean training reward over the last 100 episodes\n",
        "                mean_reward = np.mean(y[-100:])\n",
        "                if self.verbose > 0:\n",
        "                    print(\"Num timesteps: {}\".format(self.num_timesteps))\n",
        "                    print(\n",
        "                        \"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f}\".format(\n",
        "                            self.best_mean_reward, mean_reward\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "                # New best model, you could save the agent here\n",
        "                if mean_reward > self.best_mean_reward:\n",
        "                    self.best_mean_reward = mean_reward\n",
        "                    # Example for saving best model\n",
        "                    if self.verbose > 0:\n",
        "                        print(\"Saving new best model at {} timesteps\".format(x[-1]))\n",
        "                        print(\"Saving new best model to {}.zip\".format(self.save_path))\n",
        "                    self.model.save(self.save_path)\n",
        "\n",
        "        return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQIWMuY-XqEV"
      },
      "outputs": [],
      "source": [
        "# Create log dir\n",
        "log_dir = \"/tmp/gym/\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = make_vec_env(\"CartPole-v1\", n_envs=1, monitor_dir=log_dir)\n",
        "# it is equivalent to:\n",
        "# env = gym.make('CartPole-v1')\n",
        "# env = Monitor(env, log_dir)\n",
        "# env = DummyVecEnv([lambda: env])\n",
        "\n",
        "# Create Callback\n",
        "callback = SaveOnBestTrainingRewardCallback(check_freq=20, log_dir=log_dir, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMxVWNqRbt8G"
      },
      "outputs": [],
      "source": [
        "train_env = SubprocVecEnv(\n",
        "        [make_env(df, i + 15) for i in range(8)],\n",
        "        start_method=\"fork\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8C69kQJlfRX",
        "outputId": "c0a10372-fcbb-4ab0-e360-3cd6ca46d5e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sb3_contrib\n",
            "  Downloading sb3_contrib-2.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: stable-baselines3<3.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from sb3_contrib) (2.4.0)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0->sb3_contrib) (1.0.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0->sb3_contrib) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0->sb3_contrib) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0->sb3_contrib) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0->sb3_contrib) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0->sb3_contrib) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3<3.0,>=2.4.0->sb3_contrib) (3.0.2)\n",
            "Downloading sb3_contrib-2.4.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sb3_contrib\n",
            "Successfully installed sb3_contrib-2.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install sb3_contrib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MHfbukTlYwK"
      },
      "outputs": [],
      "source": [
        "from sb3_contrib import RecurrentPPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aIHDQWTeAoq",
        "outputId": "a0681a80-823e-4b0b-999a-5d6b2dbe3807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Num timesteps: 112780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 261.56\n",
            "Num timesteps: 112800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 261.56\n",
            "Num timesteps: 112820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 261.56\n",
            "Num timesteps: 112840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 262.99\n",
            "Num timesteps: 112860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 262.99\n",
            "Num timesteps: 112880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 262.99\n",
            "Num timesteps: 112900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 262.99\n",
            "Num timesteps: 112920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 262.99\n",
            "Num timesteps: 112940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 262.99\n",
            "Num timesteps: 112960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 262.99\n",
            "Num timesteps: 112980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 262.99\n",
            "Num timesteps: 113000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 262.99\n",
            "Num timesteps: 113020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 262.99\n",
            "Num timesteps: 113040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 262.99\n",
            "Num timesteps: 113060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 262.99\n",
            "Num timesteps: 113080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 262.99\n",
            "Num timesteps: 113100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.18\n",
            "Num timesteps: 113380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 265.40\n",
            "Num timesteps: 113400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 265.40\n",
            "Num timesteps: 113420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 265.40\n",
            "Num timesteps: 113440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 265.40\n",
            "Num timesteps: 113460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 265.40\n",
            "Num timesteps: 113480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 265.40\n",
            "Num timesteps: 113500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 265.40\n",
            "Num timesteps: 113520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 265.40\n",
            "Num timesteps: 113540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 265.40\n",
            "Num timesteps: 113560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 265.40\n",
            "Num timesteps: 113580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 265.40\n",
            "Num timesteps: 113600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.08\n",
            "Num timesteps: 113620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.08\n",
            "Num timesteps: 113640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.08\n",
            "Num timesteps: 113660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.08\n",
            "Num timesteps: 113680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.08\n",
            "Num timesteps: 113700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.08\n",
            "Num timesteps: 113720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.08\n",
            "Num timesteps: 113740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.08\n",
            "Num timesteps: 113760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.08\n",
            "Num timesteps: 113780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.08\n",
            "Num timesteps: 113800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.08\n",
            "Num timesteps: 113820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.80\n",
            "Num timesteps: 113840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.80\n",
            "Num timesteps: 113860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.80\n",
            "Num timesteps: 113880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.80\n",
            "Num timesteps: 113900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.80\n",
            "Num timesteps: 113920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.80\n",
            "Num timesteps: 113940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.80\n",
            "Num timesteps: 113960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.80\n",
            "Num timesteps: 113980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.80\n",
            "Num timesteps: 114000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.80\n",
            "Num timesteps: 114020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 266.80\n",
            "Num timesteps: 114040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.47\n",
            "Num timesteps: 114060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.47\n",
            "Num timesteps: 114080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.47\n",
            "Num timesteps: 114100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.47\n",
            "Num timesteps: 114120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.47\n",
            "Num timesteps: 114140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.47\n",
            "Num timesteps: 114160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.47\n",
            "Num timesteps: 114180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.47\n",
            "Num timesteps: 114200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.47\n",
            "Num timesteps: 114220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.70\n",
            "Num timesteps: 114240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.70\n",
            "Num timesteps: 114260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.70\n",
            "Num timesteps: 114280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.70\n",
            "Num timesteps: 114300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.70\n",
            "Num timesteps: 114320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.70\n",
            "Num timesteps: 114340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.70\n",
            "Num timesteps: 114360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.70\n",
            "Num timesteps: 114380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 267.70\n",
            "Num timesteps: 114400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.26\n",
            "Num timesteps: 114420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.26\n",
            "Num timesteps: 114440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.26\n",
            "Num timesteps: 114460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.26\n",
            "Num timesteps: 114480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.26\n",
            "Num timesteps: 114500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.26\n",
            "Num timesteps: 114520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.26\n",
            "Num timesteps: 114540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.03\n",
            "Num timesteps: 114560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.03\n",
            "Num timesteps: 114580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.03\n",
            "Num timesteps: 114600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.03\n",
            "Num timesteps: 114620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.03\n",
            "Num timesteps: 114640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.03\n",
            "Num timesteps: 114660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.03\n",
            "Num timesteps: 114680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.32\n",
            "Num timesteps: 114700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.32\n",
            "Num timesteps: 114720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.32\n",
            "Num timesteps: 114740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.32\n",
            "Num timesteps: 114760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.32\n",
            "Num timesteps: 114780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.32\n",
            "Num timesteps: 114800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.32\n",
            "Num timesteps: 114820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.32\n",
            "Num timesteps: 114840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.32\n",
            "Num timesteps: 114860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.61\n",
            "Num timesteps: 114880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.61\n",
            "Num timesteps: 114900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.61\n",
            "Num timesteps: 114920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.61\n",
            "Num timesteps: 114940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.61\n",
            "Num timesteps: 114960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.61\n",
            "Num timesteps: 114980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.61\n",
            "Num timesteps: 115000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.72\n",
            "Num timesteps: 115020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.72\n",
            "Num timesteps: 115040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.72\n",
            "Num timesteps: 115060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.72\n",
            "Num timesteps: 115080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.72\n",
            "Num timesteps: 115100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.72\n",
            "Num timesteps: 115120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.72\n",
            "Num timesteps: 115140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.72\n",
            "Num timesteps: 115160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.72\n",
            "Num timesteps: 115180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.82\n",
            "Num timesteps: 115200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.82\n",
            "Num timesteps: 115220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.82\n",
            "Num timesteps: 115240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.82\n",
            "Num timesteps: 115260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.82\n",
            "Num timesteps: 115280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.82\n",
            "Num timesteps: 115300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.82\n",
            "Num timesteps: 115320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.68\n",
            "Num timesteps: 115340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.68\n",
            "Num timesteps: 115360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.68\n",
            "Num timesteps: 115380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.68\n",
            "Num timesteps: 115400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.68\n",
            "Num timesteps: 115420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.68\n",
            "Num timesteps: 115440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.68\n",
            "Num timesteps: 115460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.68\n",
            "Num timesteps: 115480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.51\n",
            "Num timesteps: 115500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.51\n",
            "Num timesteps: 115520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.51\n",
            "Num timesteps: 115540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.51\n",
            "Num timesteps: 115560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.51\n",
            "Num timesteps: 115580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.51\n",
            "Num timesteps: 115600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.51\n",
            "Num timesteps: 115620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.36\n",
            "Num timesteps: 115640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.36\n",
            "Num timesteps: 115660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.36\n",
            "Num timesteps: 115680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.36\n",
            "Num timesteps: 115700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.36\n",
            "Num timesteps: 115720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.36\n",
            "Num timesteps: 115740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.36\n",
            "Num timesteps: 115760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.01\n",
            "Num timesteps: 115780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.01\n",
            "Num timesteps: 115800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.01\n",
            "Num timesteps: 115820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.01\n",
            "Num timesteps: 115840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.01\n",
            "Num timesteps: 115860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.01\n",
            "Num timesteps: 115880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.01\n",
            "Num timesteps: 115900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.72\n",
            "Num timesteps: 115920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.72\n",
            "Num timesteps: 115940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.72\n",
            "Num timesteps: 115960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.72\n",
            "Num timesteps: 115980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.72\n",
            "Num timesteps: 116000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.72\n",
            "Num timesteps: 116020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.72\n",
            "Num timesteps: 116040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 269.72\n",
            "Num timesteps: 116060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.54\n",
            "Num timesteps: 116080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.54\n",
            "Num timesteps: 116100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.54\n",
            "Num timesteps: 116120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.54\n",
            "Num timesteps: 116140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.54\n",
            "Num timesteps: 116160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.54\n",
            "Num timesteps: 116180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.54\n",
            "Num timesteps: 116200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 270.54\n",
            "Num timesteps: 116220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 271.63\n",
            "Num timesteps: 116240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 271.63\n",
            "Num timesteps: 116260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 271.63\n",
            "Num timesteps: 116280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 271.63\n",
            "Num timesteps: 116300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 271.63\n",
            "Num timesteps: 116320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 271.63\n",
            "Num timesteps: 116340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 271.63\n",
            "Num timesteps: 116360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.47\n",
            "Num timesteps: 116380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.47\n",
            "Num timesteps: 116400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.47\n",
            "Num timesteps: 116420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.47\n",
            "Num timesteps: 116440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.47\n",
            "Num timesteps: 116460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.47\n",
            "Num timesteps: 116480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.47\n",
            "Num timesteps: 116500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.47\n",
            "Num timesteps: 116520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.33\n",
            "Num timesteps: 116540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.33\n",
            "Num timesteps: 116560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.33\n",
            "Num timesteps: 116580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.33\n",
            "Num timesteps: 116600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.33\n",
            "Num timesteps: 116620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.33\n",
            "Num timesteps: 116640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.33\n",
            "Num timesteps: 116660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.99\n",
            "Num timesteps: 116680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.99\n",
            "Num timesteps: 116700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.99\n",
            "Num timesteps: 116720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.99\n",
            "Num timesteps: 116740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.99\n",
            "Num timesteps: 116760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.99\n",
            "Num timesteps: 116780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 273.99\n",
            "Num timesteps: 116800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 274.78\n",
            "Num timesteps: 116820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 274.78\n",
            "Num timesteps: 116840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 274.78\n",
            "Num timesteps: 116860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 274.78\n",
            "Num timesteps: 116880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 274.78\n",
            "Num timesteps: 116900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 274.78\n",
            "Num timesteps: 116920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.36\n",
            "Num timesteps: 116940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.36\n",
            "Num timesteps: 116960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.36\n",
            "Num timesteps: 116980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.36\n",
            "Num timesteps: 117000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.36\n",
            "Num timesteps: 117020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.36\n",
            "Num timesteps: 117040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.36\n",
            "Num timesteps: 117060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.61\n",
            "Num timesteps: 117080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.61\n",
            "Num timesteps: 117100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.61\n",
            "Num timesteps: 117120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.61\n",
            "Num timesteps: 117140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.61\n",
            "Num timesteps: 117160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.61\n",
            "Num timesteps: 117180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.88\n",
            "Num timesteps: 117200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.88\n",
            "Num timesteps: 117220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.88\n",
            "Num timesteps: 117240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.88\n",
            "Num timesteps: 117260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.88\n",
            "Num timesteps: 117280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.88\n",
            "Num timesteps: 117300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.87\n",
            "Num timesteps: 117320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.87\n",
            "Num timesteps: 117340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.87\n",
            "Num timesteps: 117360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.87\n",
            "Num timesteps: 117380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.87\n",
            "Num timesteps: 117400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.87\n",
            "Num timesteps: 117420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.87\n",
            "Num timesteps: 117440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.79\n",
            "Num timesteps: 117460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.79\n",
            "Num timesteps: 117480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.79\n",
            "Num timesteps: 117500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.79\n",
            "Num timesteps: 117520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.79\n",
            "Num timesteps: 117540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.79\n",
            "Num timesteps: 117560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.69\n",
            "Num timesteps: 117580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.69\n",
            "Num timesteps: 117600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.69\n",
            "Num timesteps: 117620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.69\n",
            "Num timesteps: 117640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.69\n",
            "Num timesteps: 117660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.69\n",
            "Num timesteps: 117680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.56\n",
            "Num timesteps: 117700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.56\n",
            "Num timesteps: 117720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.56\n",
            "Num timesteps: 117740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.56\n",
            "Num timesteps: 117760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.56\n",
            "Num timesteps: 117780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.56\n",
            "Num timesteps: 117800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.22\n",
            "Num timesteps: 117820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.22\n",
            "Num timesteps: 117840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.22\n",
            "Num timesteps: 117860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.22\n",
            "Num timesteps: 117880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.22\n",
            "Num timesteps: 117900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.22\n",
            "Num timesteps: 117920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.22\n",
            "Num timesteps: 117940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.15\n",
            "Num timesteps: 117960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.15\n",
            "Num timesteps: 117980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.15\n",
            "Num timesteps: 118000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.15\n",
            "Num timesteps: 118020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.15\n",
            "Num timesteps: 118040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.15\n",
            "Num timesteps: 118060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 275.15\n",
            "Num timesteps: 118080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 274.30\n",
            "Num timesteps: 118100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 274.30\n",
            "Num timesteps: 118120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 274.30\n",
            "Num timesteps: 118140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 274.30\n",
            "Num timesteps: 118160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 274.30\n",
            "Num timesteps: 118180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 274.30\n",
            "Num timesteps: 118200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.22\n",
            "Num timesteps: 118220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.22\n",
            "Num timesteps: 118240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.22\n",
            "Num timesteps: 118260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.22\n",
            "Num timesteps: 118280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.22\n",
            "Num timesteps: 118300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.22\n",
            "Num timesteps: 118320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 272.22\n",
            "Num timesteps: 118340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 268.53\n",
            "Num timesteps: 118360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 268.53\n",
            "Num timesteps: 118380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 268.53\n",
            "Num timesteps: 118400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 268.53\n",
            "Num timesteps: 118420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 268.53\n",
            "Num timesteps: 118440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 268.53\n",
            "Num timesteps: 118460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.79\n",
            "Num timesteps: 118480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.79\n",
            "Num timesteps: 118500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.79\n",
            "Num timesteps: 118520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.79\n",
            "Num timesteps: 118540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.79\n",
            "Num timesteps: 118560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.79\n",
            "Num timesteps: 118580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 264.79\n",
            "Num timesteps: 118600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 261.15\n",
            "Num timesteps: 118620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 261.15\n",
            "Num timesteps: 118640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 261.15\n",
            "Num timesteps: 118660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 261.15\n",
            "Num timesteps: 118680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 261.15\n",
            "Num timesteps: 118700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 261.15\n",
            "Num timesteps: 118720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 257.42\n",
            "Num timesteps: 118740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 257.42\n",
            "Num timesteps: 118760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 257.42\n",
            "Num timesteps: 118780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 257.42\n",
            "Num timesteps: 118800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 257.42\n",
            "Num timesteps: 118820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 257.42\n",
            "Num timesteps: 118840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 257.42\n",
            "Num timesteps: 118860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 255.00\n",
            "Num timesteps: 118880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 255.00\n",
            "Num timesteps: 118900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 255.00\n",
            "Num timesteps: 118920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 255.00\n",
            "Num timesteps: 118940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 255.00\n",
            "Num timesteps: 118960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 255.00\n",
            "Num timesteps: 118980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 255.00\n",
            "Num timesteps: 119000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 252.69\n",
            "Num timesteps: 119020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 252.69\n",
            "Num timesteps: 119040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 252.69\n",
            "Num timesteps: 119060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 252.69\n",
            "Num timesteps: 119080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 252.69\n",
            "Num timesteps: 119100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 252.69\n",
            "Num timesteps: 119120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 250.15\n",
            "Num timesteps: 119140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 250.15\n",
            "Num timesteps: 119160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 250.15\n",
            "Num timesteps: 119180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 250.15\n",
            "Num timesteps: 119200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 250.15\n",
            "Num timesteps: 119220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 250.15\n",
            "Num timesteps: 119240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 248.84\n",
            "Num timesteps: 119260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 248.84\n",
            "Num timesteps: 119280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 248.84\n",
            "Num timesteps: 119300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 248.84\n",
            "Num timesteps: 119320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 248.84\n",
            "Num timesteps: 119340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 248.84\n",
            "Num timesteps: 119360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 248.84\n",
            "Num timesteps: 119380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 247.50\n",
            "Num timesteps: 119400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 247.50\n",
            "Num timesteps: 119420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 247.50\n",
            "Num timesteps: 119440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 247.50\n",
            "Num timesteps: 119460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 247.50\n",
            "Num timesteps: 119480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 247.50\n",
            "Num timesteps: 119500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 246.19\n",
            "Num timesteps: 119520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 246.19\n",
            "Num timesteps: 119540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 246.19\n",
            "Num timesteps: 119560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 246.19\n",
            "Num timesteps: 119580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 246.19\n",
            "Num timesteps: 119600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 246.19\n",
            "Num timesteps: 119620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 246.19\n",
            "Num timesteps: 119640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 244.71\n",
            "Num timesteps: 119660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 244.71\n",
            "Num timesteps: 119680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 244.71\n",
            "Num timesteps: 119700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 244.71\n",
            "Num timesteps: 119720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 244.71\n",
            "Num timesteps: 119740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 244.71\n",
            "Num timesteps: 119760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 243.33\n",
            "Num timesteps: 119780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 243.33\n",
            "Num timesteps: 119800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 243.33\n",
            "Num timesteps: 119820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 243.33\n",
            "Num timesteps: 119840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 243.33\n",
            "Num timesteps: 119860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 243.33\n",
            "Num timesteps: 119880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 241.99\n",
            "Num timesteps: 119900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 241.99\n",
            "Num timesteps: 119920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 241.99\n",
            "Num timesteps: 119940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 241.99\n",
            "Num timesteps: 119960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 241.99\n",
            "Num timesteps: 119980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 241.99\n",
            "Num timesteps: 120000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 241.99\n",
            "Num timesteps: 120020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 239.77\n",
            "Num timesteps: 120040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 239.77\n",
            "Num timesteps: 120060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 239.77\n",
            "Num timesteps: 120080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 239.77\n",
            "Num timesteps: 120100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 239.77\n",
            "Num timesteps: 120120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 239.77\n",
            "Num timesteps: 120140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 236.98\n",
            "Num timesteps: 120160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 236.98\n",
            "Num timesteps: 120180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 236.98\n",
            "Num timesteps: 120200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 236.98\n",
            "Num timesteps: 120220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 236.98\n",
            "Num timesteps: 120240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 236.98\n",
            "Num timesteps: 120260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 236.98\n",
            "Num timesteps: 120280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 235.33\n",
            "Num timesteps: 120300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 235.33\n",
            "Num timesteps: 120320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 235.33\n",
            "Num timesteps: 120340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 235.33\n",
            "Num timesteps: 120360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 235.33\n",
            "Num timesteps: 120380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 235.33\n",
            "Num timesteps: 120400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 232.09\n",
            "Num timesteps: 120420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 232.09\n",
            "Num timesteps: 120440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 232.09\n",
            "Num timesteps: 120460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 232.09\n",
            "Num timesteps: 120480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 232.09\n",
            "Num timesteps: 120500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 232.09\n",
            "Num timesteps: 120520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 229.20\n",
            "Num timesteps: 120540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 229.20\n",
            "Num timesteps: 120560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 229.20\n",
            "Num timesteps: 120580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 229.20\n",
            "Num timesteps: 120600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 229.20\n",
            "Num timesteps: 120620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 229.20\n",
            "Num timesteps: 120640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 226.55\n",
            "Num timesteps: 120660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 226.55\n",
            "Num timesteps: 120680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 226.55\n",
            "Num timesteps: 120700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 226.55\n",
            "Num timesteps: 120720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 226.55\n",
            "Num timesteps: 120740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 226.55\n",
            "Num timesteps: 120760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 224.67\n",
            "Num timesteps: 120780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 224.67\n",
            "Num timesteps: 120800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 224.67\n",
            "Num timesteps: 120820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 224.67\n",
            "Num timesteps: 120840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 224.67\n",
            "Num timesteps: 120860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 224.67\n",
            "Num timesteps: 120880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 223.53\n",
            "Num timesteps: 120900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 223.53\n",
            "Num timesteps: 120920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 223.53\n",
            "Num timesteps: 120940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 223.53\n",
            "Num timesteps: 120960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 223.53\n",
            "Num timesteps: 120980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 223.53\n",
            "Num timesteps: 121000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 222.08\n",
            "Num timesteps: 121020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 222.08\n",
            "Num timesteps: 121040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 222.08\n",
            "Num timesteps: 121060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 222.08\n",
            "Num timesteps: 121080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 222.08\n",
            "Num timesteps: 121100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 222.08\n",
            "Num timesteps: 121120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 220.33\n",
            "Num timesteps: 121140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 220.33\n",
            "Num timesteps: 121160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 220.33\n",
            "Num timesteps: 121180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 220.33\n",
            "Num timesteps: 121200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 220.33\n",
            "Num timesteps: 121220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 220.33\n",
            "Num timesteps: 121240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 220.33\n",
            "Num timesteps: 121260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 218.05\n",
            "Num timesteps: 121280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 218.05\n",
            "Num timesteps: 121300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 218.05\n",
            "Num timesteps: 121320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 218.05\n",
            "Num timesteps: 121340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 218.05\n",
            "Num timesteps: 121360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 218.05\n",
            "Num timesteps: 121380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 215.36\n",
            "Num timesteps: 121400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 215.36\n",
            "Num timesteps: 121420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 215.36\n",
            "Num timesteps: 121440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 215.36\n",
            "Num timesteps: 121460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 215.36\n",
            "Num timesteps: 121480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 215.36\n",
            "Num timesteps: 121500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 213.57\n",
            "Num timesteps: 121520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 213.57\n",
            "Num timesteps: 121540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 213.57\n",
            "Num timesteps: 121560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 213.57\n",
            "Num timesteps: 121580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 213.57\n",
            "Num timesteps: 121600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 213.57\n",
            "Num timesteps: 121620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 213.57\n",
            "Num timesteps: 121640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 212.46\n",
            "Num timesteps: 121660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 212.46\n",
            "Num timesteps: 121680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 212.46\n",
            "Num timesteps: 121700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 212.46\n",
            "Num timesteps: 121720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 212.46\n",
            "Num timesteps: 121740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 212.46\n",
            "Num timesteps: 121760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 212.46\n",
            "Num timesteps: 121780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 211.90\n",
            "Num timesteps: 121800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 211.90\n",
            "Num timesteps: 121820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 211.90\n",
            "Num timesteps: 121840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 211.90\n",
            "Num timesteps: 121860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 211.90\n",
            "Num timesteps: 121880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 211.90\n",
            "Num timesteps: 121900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 211.25\n",
            "Num timesteps: 121920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 211.25\n",
            "Num timesteps: 121940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 211.25\n",
            "Num timesteps: 121960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 211.25\n",
            "Num timesteps: 121980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 211.25\n",
            "Num timesteps: 122000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 211.25\n",
            "Num timesteps: 122020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 210.17\n",
            "Num timesteps: 122040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 210.17\n",
            "Num timesteps: 122060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 210.17\n",
            "Num timesteps: 122080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 210.17\n",
            "Num timesteps: 122100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 210.17\n",
            "Num timesteps: 122120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 210.17\n",
            "Num timesteps: 122140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 210.17\n",
            "Num timesteps: 122160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 209.45\n",
            "Num timesteps: 122180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 209.45\n",
            "Num timesteps: 122200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 209.45\n",
            "Num timesteps: 122220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 209.45\n",
            "Num timesteps: 122240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 209.45\n",
            "Num timesteps: 122260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 209.45\n",
            "Num timesteps: 122280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 208.31\n",
            "Num timesteps: 122300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 208.31\n",
            "Num timesteps: 122320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 208.31\n",
            "Num timesteps: 122340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 208.31\n",
            "Num timesteps: 122360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 208.31\n",
            "Num timesteps: 122380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 208.31\n",
            "Num timesteps: 122400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 207.56\n",
            "Num timesteps: 122420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 207.56\n",
            "Num timesteps: 122440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 207.56\n",
            "Num timesteps: 122460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 207.56\n",
            "Num timesteps: 122480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 207.56\n",
            "Num timesteps: 122500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 207.56\n",
            "Num timesteps: 122520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 206.69\n",
            "Num timesteps: 122540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 206.69\n",
            "Num timesteps: 122560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 206.69\n",
            "Num timesteps: 122580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 206.69\n",
            "Num timesteps: 122600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 206.69\n",
            "Num timesteps: 122620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 206.69\n",
            "Num timesteps: 122640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 205.64\n",
            "Num timesteps: 122660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 205.64\n",
            "Num timesteps: 122680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 205.64\n",
            "Num timesteps: 122700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 205.64\n",
            "Num timesteps: 122720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 205.64\n",
            "Num timesteps: 122740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 205.64\n",
            "Num timesteps: 122760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 204.06\n",
            "Num timesteps: 122780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 204.06\n",
            "Num timesteps: 122800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 204.06\n",
            "Num timesteps: 122820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 204.06\n",
            "Num timesteps: 122840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 204.06\n",
            "Num timesteps: 122860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 204.06\n",
            "Num timesteps: 122880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 201.42\n",
            "Num timesteps: 122900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 196.57\n",
            "Num timesteps: 122920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 196.57\n",
            "Num timesteps: 122940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 196.57\n",
            "Num timesteps: 122960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 196.57\n",
            "Num timesteps: 122980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 196.57\n",
            "Num timesteps: 123000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 196.57\n",
            "Num timesteps: 123020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 192.72\n",
            "Num timesteps: 123040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 192.72\n",
            "Num timesteps: 123060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 192.72\n",
            "Num timesteps: 123080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 192.72\n",
            "Num timesteps: 123100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 192.72\n",
            "Num timesteps: 123120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 192.72\n",
            "Num timesteps: 123140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 190.11\n",
            "Num timesteps: 123160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 190.11\n",
            "Num timesteps: 123180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 190.11\n",
            "Num timesteps: 123200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 190.11\n",
            "Num timesteps: 123220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 190.11\n",
            "Num timesteps: 123240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 190.11\n",
            "Num timesteps: 123260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.30\n",
            "Num timesteps: 123280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.30\n",
            "Num timesteps: 123300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.30\n",
            "Num timesteps: 123320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.30\n",
            "Num timesteps: 123340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.30\n",
            "Num timesteps: 123360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.30\n",
            "Num timesteps: 123380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.68\n",
            "Num timesteps: 123400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.68\n",
            "Num timesteps: 123420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.68\n",
            "Num timesteps: 123440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.68\n",
            "Num timesteps: 123460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.68\n",
            "Num timesteps: 123480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.68\n",
            "Num timesteps: 123500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.02\n",
            "Num timesteps: 123520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.02\n",
            "Num timesteps: 123540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.02\n",
            "Num timesteps: 123560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.02\n",
            "Num timesteps: 123580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.02\n",
            "Num timesteps: 123600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.02\n",
            "Num timesteps: 123620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.73\n",
            "Num timesteps: 123640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.73\n",
            "Num timesteps: 123660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.73\n",
            "Num timesteps: 123680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.73\n",
            "Num timesteps: 123700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.73\n",
            "Num timesteps: 123720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.73\n",
            "Num timesteps: 123740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.00\n",
            "Num timesteps: 123760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.00\n",
            "Num timesteps: 123780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.00\n",
            "Num timesteps: 123800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.00\n",
            "Num timesteps: 123820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.00\n",
            "Num timesteps: 123840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.00\n",
            "Num timesteps: 123860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 178.86\n",
            "Num timesteps: 123880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 178.86\n",
            "Num timesteps: 123900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 178.86\n",
            "Num timesteps: 123920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 178.86\n",
            "Num timesteps: 123940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 178.86\n",
            "Num timesteps: 123960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 178.86\n",
            "Num timesteps: 123980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 178.86\n",
            "Num timesteps: 124000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.96\n",
            "Num timesteps: 124020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.96\n",
            "Num timesteps: 124040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.96\n",
            "Num timesteps: 124060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.96\n",
            "Num timesteps: 124080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.96\n",
            "Num timesteps: 124100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.96\n",
            "Num timesteps: 124120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.96\n",
            "Num timesteps: 124140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.46\n",
            "Num timesteps: 124160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.46\n",
            "Num timesteps: 124180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.46\n",
            "Num timesteps: 124200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.46\n",
            "Num timesteps: 124220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.46\n",
            "Num timesteps: 124240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.46\n",
            "Num timesteps: 124260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.59\n",
            "Num timesteps: 124280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.59\n",
            "Num timesteps: 124300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.59\n",
            "Num timesteps: 124320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.59\n",
            "Num timesteps: 124340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.59\n",
            "Num timesteps: 124360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.59\n",
            "Num timesteps: 124380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.59\n",
            "Num timesteps: 124400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.59\n",
            "Num timesteps: 124420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.87\n",
            "Num timesteps: 124440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.87\n",
            "Num timesteps: 124460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.87\n",
            "Num timesteps: 124480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.87\n",
            "Num timesteps: 124500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.87\n",
            "Num timesteps: 124520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.87\n",
            "Num timesteps: 124540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.49\n",
            "Num timesteps: 124560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.49\n",
            "Num timesteps: 124580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.49\n",
            "Num timesteps: 124600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.49\n",
            "Num timesteps: 124620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.49\n",
            "Num timesteps: 124640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.49\n",
            "Num timesteps: 124660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.49\n",
            "Num timesteps: 124680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.26\n",
            "Num timesteps: 124700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.26\n",
            "Num timesteps: 124720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.26\n",
            "Num timesteps: 124740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.26\n",
            "Num timesteps: 124760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.26\n",
            "Num timesteps: 124780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.26\n",
            "Num timesteps: 124800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.26\n",
            "Num timesteps: 124820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 164.63\n",
            "Num timesteps: 124840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 164.63\n",
            "Num timesteps: 124860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 164.63\n",
            "Num timesteps: 124880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 164.63\n",
            "Num timesteps: 124900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 164.63\n",
            "Num timesteps: 124920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 164.63\n",
            "Num timesteps: 124940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 164.63\n",
            "Num timesteps: 124960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 164.63\n",
            "Num timesteps: 124980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.29\n",
            "Num timesteps: 125000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.29\n",
            "Num timesteps: 125020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.29\n",
            "Num timesteps: 125040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.29\n",
            "Num timesteps: 125060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.29\n",
            "Num timesteps: 125080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.29\n",
            "Num timesteps: 125100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.29\n",
            "Num timesteps: 125120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.29\n",
            "Num timesteps: 125140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.29\n",
            "Num timesteps: 125160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.09\n",
            "Num timesteps: 125180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.09\n",
            "Num timesteps: 125200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.09\n",
            "Num timesteps: 125220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.09\n",
            "Num timesteps: 125240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.09\n",
            "Num timesteps: 125260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.09\n",
            "Num timesteps: 125280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.09\n",
            "Num timesteps: 125300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.09\n",
            "Num timesteps: 125320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.22\n",
            "Num timesteps: 125340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.22\n",
            "Num timesteps: 125360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.22\n",
            "Num timesteps: 125380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.22\n",
            "Num timesteps: 125400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.22\n",
            "Num timesteps: 125420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.22\n",
            "Num timesteps: 125440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.22\n",
            "Num timesteps: 125460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.22\n",
            "Num timesteps: 125480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.22\n",
            "Num timesteps: 125500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 155.40\n",
            "Num timesteps: 125520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 155.40\n",
            "Num timesteps: 125540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 155.40\n",
            "Num timesteps: 125560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 155.40\n",
            "Num timesteps: 125580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 155.40\n",
            "Num timesteps: 125600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 155.40\n",
            "Num timesteps: 125620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 155.40\n",
            "Num timesteps: 125640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.63\n",
            "Num timesteps: 125660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.63\n",
            "Num timesteps: 125680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.63\n",
            "Num timesteps: 125700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.63\n",
            "Num timesteps: 125720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.63\n",
            "Num timesteps: 125740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.63\n",
            "Num timesteps: 125760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.63\n",
            "Num timesteps: 125780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.63\n",
            "Num timesteps: 125800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.63\n",
            "Num timesteps: 125820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.86\n",
            "Num timesteps: 125840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.86\n",
            "Num timesteps: 125860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.86\n",
            "Num timesteps: 125880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.86\n",
            "Num timesteps: 125900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.86\n",
            "Num timesteps: 125920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.86\n",
            "Num timesteps: 125940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.86\n",
            "Num timesteps: 125960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.86\n",
            "Num timesteps: 125980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.27\n",
            "Num timesteps: 126000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.27\n",
            "Num timesteps: 126020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.27\n",
            "Num timesteps: 126040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.27\n",
            "Num timesteps: 126060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.27\n",
            "Num timesteps: 126080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.27\n",
            "Num timesteps: 126100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.27\n",
            "Num timesteps: 126120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.27\n",
            "Num timesteps: 126140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.73\n",
            "Num timesteps: 126160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.73\n",
            "Num timesteps: 126180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.73\n",
            "Num timesteps: 126200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.73\n",
            "Num timesteps: 126220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.73\n",
            "Num timesteps: 126240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.73\n",
            "Num timesteps: 126260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.73\n",
            "Num timesteps: 126280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.73\n",
            "Num timesteps: 126300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.73\n",
            "Num timesteps: 126320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.19\n",
            "Num timesteps: 126340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.19\n",
            "Num timesteps: 126360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.19\n",
            "Num timesteps: 126380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.19\n",
            "Num timesteps: 126400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.19\n",
            "Num timesteps: 126420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.19\n",
            "Num timesteps: 126440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.19\n",
            "Num timesteps: 126460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.19\n",
            "Num timesteps: 126480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.19\n",
            "Num timesteps: 126500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.19\n",
            "Num timesteps: 126520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.34\n",
            "Num timesteps: 126540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.34\n",
            "Num timesteps: 126560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.34\n",
            "Num timesteps: 126580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.34\n",
            "Num timesteps: 126600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.34\n",
            "Num timesteps: 126620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.34\n",
            "Num timesteps: 126640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.34\n",
            "Num timesteps: 126660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.13\n",
            "Num timesteps: 126680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.13\n",
            "Num timesteps: 126700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.13\n",
            "Num timesteps: 126720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.13\n",
            "Num timesteps: 126740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.13\n",
            "Num timesteps: 126760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.13\n",
            "Num timesteps: 126780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.13\n",
            "Num timesteps: 126800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.13\n",
            "Num timesteps: 126820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.13\n",
            "Num timesteps: 126840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.12\n",
            "Num timesteps: 126860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.12\n",
            "Num timesteps: 126880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.12\n",
            "Num timesteps: 126900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.12\n",
            "Num timesteps: 126920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.12\n",
            "Num timesteps: 126940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.12\n",
            "Num timesteps: 126960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.12\n",
            "Num timesteps: 126980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.12\n",
            "Num timesteps: 127000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.12\n",
            "Num timesteps: 127020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.82\n",
            "Num timesteps: 127040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.82\n",
            "Num timesteps: 127060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.82\n",
            "Num timesteps: 127080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.82\n",
            "Num timesteps: 127100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.82\n",
            "Num timesteps: 127120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.82\n",
            "Num timesteps: 127140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.82\n",
            "Num timesteps: 127160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.82\n",
            "Num timesteps: 127180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.85\n",
            "Num timesteps: 127200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.85\n",
            "Num timesteps: 127220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.85\n",
            "Num timesteps: 127240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.85\n",
            "Num timesteps: 127260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.85\n",
            "Num timesteps: 127280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.85\n",
            "Num timesteps: 127300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.85\n",
            "Num timesteps: 127320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.85\n",
            "Num timesteps: 127340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.85\n",
            "Num timesteps: 127360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.85\n",
            "Num timesteps: 127380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.09\n",
            "Num timesteps: 127400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.09\n",
            "Num timesteps: 127420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.09\n",
            "Num timesteps: 127440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.09\n",
            "Num timesteps: 127460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.09\n",
            "Num timesteps: 127480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.09\n",
            "Num timesteps: 127500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.09\n",
            "Num timesteps: 127520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.09\n",
            "Num timesteps: 127540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.09\n",
            "Num timesteps: 127560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.71\n",
            "Num timesteps: 127580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.71\n",
            "Num timesteps: 127600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.71\n",
            "Num timesteps: 127620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.71\n",
            "Num timesteps: 127640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.71\n",
            "Num timesteps: 127660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.71\n",
            "Num timesteps: 127680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.71\n",
            "Num timesteps: 127700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.71\n",
            "Num timesteps: 127720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.71\n",
            "Num timesteps: 127740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.71\n",
            "Num timesteps: 127760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.39\n",
            "Num timesteps: 127780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.39\n",
            "Num timesteps: 127800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.39\n",
            "Num timesteps: 127820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.39\n",
            "Num timesteps: 127840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.39\n",
            "Num timesteps: 127860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.39\n",
            "Num timesteps: 127880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.39\n",
            "Num timesteps: 127900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.39\n",
            "Num timesteps: 127920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.83\n",
            "Num timesteps: 127940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.83\n",
            "Num timesteps: 127960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.83\n",
            "Num timesteps: 127980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.83\n",
            "Num timesteps: 128000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.83\n",
            "Num timesteps: 128020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.83\n",
            "Num timesteps: 128040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.83\n",
            "Num timesteps: 128060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.83\n",
            "Num timesteps: 128080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.83\n",
            "Num timesteps: 128100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.89\n",
            "Num timesteps: 128120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.89\n",
            "Num timesteps: 128140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.89\n",
            "Num timesteps: 128160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.89\n",
            "Num timesteps: 128180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.89\n",
            "Num timesteps: 128200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.89\n",
            "Num timesteps: 128220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.89\n",
            "Num timesteps: 128240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.89\n",
            "Num timesteps: 128260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.89\n",
            "Num timesteps: 128280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.74\n",
            "Num timesteps: 128300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.74\n",
            "Num timesteps: 128320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.74\n",
            "Num timesteps: 128340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.74\n",
            "Num timesteps: 128360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.74\n",
            "Num timesteps: 128380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.74\n",
            "Num timesteps: 128400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.74\n",
            "Num timesteps: 128420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.74\n",
            "Num timesteps: 128440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.74\n",
            "Num timesteps: 128460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.23\n",
            "Num timesteps: 128480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.23\n",
            "Num timesteps: 128500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.23\n",
            "Num timesteps: 128520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.23\n",
            "Num timesteps: 128540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.23\n",
            "Num timesteps: 128560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.23\n",
            "Num timesteps: 128580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.23\n",
            "Num timesteps: 128600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.23\n",
            "Num timesteps: 128620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.23\n",
            "Num timesteps: 128640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.23\n",
            "Num timesteps: 128660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.83\n",
            "Num timesteps: 128680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.83\n",
            "Num timesteps: 128700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.83\n",
            "Num timesteps: 128720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.83\n",
            "Num timesteps: 128740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.83\n",
            "Num timesteps: 128760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.83\n",
            "Num timesteps: 128780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.83\n",
            "Num timesteps: 128800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.83\n",
            "Num timesteps: 128820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.83\n",
            "Num timesteps: 128840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.81\n",
            "Num timesteps: 128860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.81\n",
            "Num timesteps: 128880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.81\n",
            "Num timesteps: 128900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.81\n",
            "Num timesteps: 128920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.81\n",
            "Num timesteps: 128940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.81\n",
            "Num timesteps: 128960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.81\n",
            "Num timesteps: 128980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.81\n",
            "Num timesteps: 129000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.81\n",
            "Num timesteps: 129020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 139.81\n",
            "Num timesteps: 129040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.40\n",
            "Num timesteps: 129060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.40\n",
            "Num timesteps: 129080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.40\n",
            "Num timesteps: 129100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.40\n",
            "Num timesteps: 129120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.40\n",
            "Num timesteps: 129140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.40\n",
            "Num timesteps: 129160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.40\n",
            "Num timesteps: 129180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.40\n",
            "Num timesteps: 129200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.40\n",
            "Num timesteps: 129220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.40\n",
            "Num timesteps: 129240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.64\n",
            "Num timesteps: 129260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.64\n",
            "Num timesteps: 129280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.64\n",
            "Num timesteps: 129300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.64\n",
            "Num timesteps: 129320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.64\n",
            "Num timesteps: 129340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.64\n",
            "Num timesteps: 129360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.64\n",
            "Num timesteps: 129380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.64\n",
            "Num timesteps: 129400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.64\n",
            "Num timesteps: 129420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.64\n",
            "Num timesteps: 129440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.11\n",
            "Num timesteps: 129460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.11\n",
            "Num timesteps: 129480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.11\n",
            "Num timesteps: 129500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.11\n",
            "Num timesteps: 129520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.11\n",
            "Num timesteps: 129540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.11\n",
            "Num timesteps: 129560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.11\n",
            "Num timesteps: 129580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.11\n",
            "Num timesteps: 129600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.11\n",
            "Num timesteps: 129620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.38\n",
            "Num timesteps: 129640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.38\n",
            "Num timesteps: 129660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.38\n",
            "Num timesteps: 129680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.38\n",
            "Num timesteps: 129700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.38\n",
            "Num timesteps: 129720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.38\n",
            "Num timesteps: 129740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.38\n",
            "Num timesteps: 129760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.38\n",
            "Num timesteps: 129780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.38\n",
            "Num timesteps: 129800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.86\n",
            "Num timesteps: 129820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.86\n",
            "Num timesteps: 129840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.86\n",
            "Num timesteps: 129860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.86\n",
            "Num timesteps: 129880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.86\n",
            "Num timesteps: 129900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.86\n",
            "Num timesteps: 129920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.86\n",
            "Num timesteps: 129940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.86\n",
            "Num timesteps: 129960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.86\n",
            "Num timesteps: 129980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.86\n",
            "Num timesteps: 130000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.86\n",
            "Num timesteps: 130020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.62\n",
            "Num timesteps: 130040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.62\n",
            "Num timesteps: 130060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.62\n",
            "Num timesteps: 130080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.62\n",
            "Num timesteps: 130100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.62\n",
            "Num timesteps: 130120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.62\n",
            "Num timesteps: 130140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.62\n",
            "Num timesteps: 130160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.62\n",
            "Num timesteps: 130180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.62\n",
            "Num timesteps: 130200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.62\n",
            "Num timesteps: 130220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.62\n",
            "Num timesteps: 130240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.29\n",
            "Num timesteps: 130260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.29\n",
            "Num timesteps: 130280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.29\n",
            "Num timesteps: 130300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.29\n",
            "Num timesteps: 130320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.29\n",
            "Num timesteps: 130340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.29\n",
            "Num timesteps: 130360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.29\n",
            "Num timesteps: 130380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.29\n",
            "Num timesteps: 130400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.42\n",
            "Num timesteps: 130420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.42\n",
            "Num timesteps: 130440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.42\n",
            "Num timesteps: 130460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.42\n",
            "Num timesteps: 130480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.42\n",
            "Num timesteps: 130500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.42\n",
            "Num timesteps: 130520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.42\n",
            "Num timesteps: 130540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.42\n",
            "Num timesteps: 130560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.49\n",
            "Num timesteps: 130580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.49\n",
            "Num timesteps: 130600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.49\n",
            "Num timesteps: 130620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.49\n",
            "Num timesteps: 130640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.49\n",
            "Num timesteps: 130660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.49\n",
            "Num timesteps: 130680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.49\n",
            "Num timesteps: 130700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.49\n",
            "Num timesteps: 130720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.59\n",
            "Num timesteps: 130740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.59\n",
            "Num timesteps: 130760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.59\n",
            "Num timesteps: 130780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.59\n",
            "Num timesteps: 130800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.59\n",
            "Num timesteps: 130820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.59\n",
            "Num timesteps: 130840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.59\n",
            "Num timesteps: 130860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.59\n",
            "Num timesteps: 130880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.59\n",
            "Num timesteps: 130900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.75\n",
            "Num timesteps: 130920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.75\n",
            "Num timesteps: 130940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.75\n",
            "Num timesteps: 130960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.75\n",
            "Num timesteps: 130980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.75\n",
            "Num timesteps: 131000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.75\n",
            "Num timesteps: 131020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.75\n",
            "Num timesteps: 131040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.75\n",
            "Num timesteps: 131060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.75\n",
            "Num timesteps: 131080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.21\n",
            "Num timesteps: 131100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.21\n",
            "Num timesteps: 131120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.21\n",
            "Num timesteps: 131140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.21\n",
            "Num timesteps: 131160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.21\n",
            "Num timesteps: 131180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.21\n",
            "Num timesteps: 131200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.21\n",
            "Num timesteps: 131220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.21\n",
            "Num timesteps: 131240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.21\n",
            "Num timesteps: 131260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.67\n",
            "Num timesteps: 131280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.67\n",
            "Num timesteps: 131300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.67\n",
            "Num timesteps: 131320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.67\n",
            "Num timesteps: 131340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.67\n",
            "Num timesteps: 131360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.67\n",
            "Num timesteps: 131380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.67\n",
            "Num timesteps: 131400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.67\n",
            "Num timesteps: 131420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.67\n",
            "Num timesteps: 131440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.14\n",
            "Num timesteps: 131460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.14\n",
            "Num timesteps: 131480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.14\n",
            "Num timesteps: 131500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.14\n",
            "Num timesteps: 131520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.14\n",
            "Num timesteps: 131540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.14\n",
            "Num timesteps: 131560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.14\n",
            "Num timesteps: 131580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.14\n",
            "Num timesteps: 131600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.42\n",
            "Num timesteps: 131620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.42\n",
            "Num timesteps: 131640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.42\n",
            "Num timesteps: 131660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.42\n",
            "Num timesteps: 131680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.42\n",
            "Num timesteps: 131700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.42\n",
            "Num timesteps: 131720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.42\n",
            "Num timesteps: 131740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.42\n",
            "Num timesteps: 131760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.84\n",
            "Num timesteps: 131780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.84\n",
            "Num timesteps: 131800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.84\n",
            "Num timesteps: 131820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.84\n",
            "Num timesteps: 131840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.84\n",
            "Num timesteps: 131860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.84\n",
            "Num timesteps: 131880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.84\n",
            "Num timesteps: 131900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.84\n",
            "Num timesteps: 131920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.12\n",
            "Num timesteps: 131940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.12\n",
            "Num timesteps: 131960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.12\n",
            "Num timesteps: 131980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.12\n",
            "Num timesteps: 132000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.12\n",
            "Num timesteps: 132020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.12\n",
            "Num timesteps: 132040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.12\n",
            "Num timesteps: 132060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.37\n",
            "Num timesteps: 132080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.37\n",
            "Num timesteps: 132100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.37\n",
            "Num timesteps: 132120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.37\n",
            "Num timesteps: 132140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.37\n",
            "Num timesteps: 132160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.37\n",
            "Num timesteps: 132180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.37\n",
            "Num timesteps: 132200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.37\n",
            "Num timesteps: 132220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.37\n",
            "Num timesteps: 132240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.92\n",
            "Num timesteps: 132260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.92\n",
            "Num timesteps: 132280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.92\n",
            "Num timesteps: 132300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.92\n",
            "Num timesteps: 132320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.92\n",
            "Num timesteps: 132340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.92\n",
            "Num timesteps: 132360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.92\n",
            "Num timesteps: 132380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.95\n",
            "Num timesteps: 132400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.95\n",
            "Num timesteps: 132420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.95\n",
            "Num timesteps: 132440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.95\n",
            "Num timesteps: 132460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.95\n",
            "Num timesteps: 132480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.95\n",
            "Num timesteps: 132500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.95\n",
            "Num timesteps: 132520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.95\n",
            "Num timesteps: 132540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.95\n",
            "Num timesteps: 132560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.95\n",
            "Num timesteps: 132580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.71\n",
            "Num timesteps: 132600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.71\n",
            "Num timesteps: 132620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.71\n",
            "Num timesteps: 132640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.71\n",
            "Num timesteps: 132660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.71\n",
            "Num timesteps: 132680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.71\n",
            "Num timesteps: 132700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.71\n",
            "Num timesteps: 132720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.71\n",
            "Num timesteps: 132740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.08\n",
            "Num timesteps: 132760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.08\n",
            "Num timesteps: 132780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.08\n",
            "Num timesteps: 132800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.08\n",
            "Num timesteps: 132820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.08\n",
            "Num timesteps: 132840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.08\n",
            "Num timesteps: 132860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.08\n",
            "Num timesteps: 132880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.08\n",
            "Num timesteps: 132900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.16\n",
            "Num timesteps: 132920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.16\n",
            "Num timesteps: 132940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.16\n",
            "Num timesteps: 132960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.16\n",
            "Num timesteps: 132980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.16\n",
            "Num timesteps: 133000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.16\n",
            "Num timesteps: 133020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.16\n",
            "Num timesteps: 133040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.16\n",
            "Num timesteps: 133060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.16\n",
            "Num timesteps: 133080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.66\n",
            "Num timesteps: 133100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.66\n",
            "Num timesteps: 133120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.66\n",
            "Num timesteps: 133140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.66\n",
            "Num timesteps: 133160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.66\n",
            "Num timesteps: 133180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.66\n",
            "Num timesteps: 133200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.66\n",
            "Num timesteps: 133220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.66\n",
            "Num timesteps: 133240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.99\n",
            "Num timesteps: 133260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.99\n",
            "Num timesteps: 133280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.99\n",
            "Num timesteps: 133300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.99\n",
            "Num timesteps: 133320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.99\n",
            "Num timesteps: 133340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.99\n",
            "Num timesteps: 133360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.99\n",
            "Num timesteps: 133380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.13\n",
            "Num timesteps: 133400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.13\n",
            "Num timesteps: 133420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.13\n",
            "Num timesteps: 133440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.13\n",
            "Num timesteps: 133460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.13\n",
            "Num timesteps: 133480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.13\n",
            "Num timesteps: 133500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.13\n",
            "Num timesteps: 133520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.26\n",
            "Num timesteps: 133540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.26\n",
            "Num timesteps: 133560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.26\n",
            "Num timesteps: 133580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.26\n",
            "Num timesteps: 133600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.26\n",
            "Num timesteps: 133620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.26\n",
            "Num timesteps: 133640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.26\n",
            "Num timesteps: 133660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.26\n",
            "Num timesteps: 133680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.51\n",
            "Num timesteps: 133700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.51\n",
            "Num timesteps: 133720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.51\n",
            "Num timesteps: 133740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.51\n",
            "Num timesteps: 133760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.51\n",
            "Num timesteps: 133780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.51\n",
            "Num timesteps: 133800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.39\n",
            "Num timesteps: 133820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.39\n",
            "Num timesteps: 133840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.39\n",
            "Num timesteps: 133860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.39\n",
            "Num timesteps: 133880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.39\n",
            "Num timesteps: 133900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.39\n",
            "Num timesteps: 133920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.33\n",
            "Num timesteps: 133940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.33\n",
            "Num timesteps: 133960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.33\n",
            "Num timesteps: 133980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.33\n",
            "Num timesteps: 134000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.33\n",
            "Num timesteps: 134020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.33\n",
            "Num timesteps: 134040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.33\n",
            "Num timesteps: 134060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.37\n",
            "Num timesteps: 134080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.37\n",
            "Num timesteps: 134100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.37\n",
            "Num timesteps: 134120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.37\n",
            "Num timesteps: 134140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.37\n",
            "Num timesteps: 134160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.37\n",
            "Num timesteps: 134180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.37\n",
            "Num timesteps: 134200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.48\n",
            "Num timesteps: 134220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.48\n",
            "Num timesteps: 134240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.48\n",
            "Num timesteps: 134260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.48\n",
            "Num timesteps: 134280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.48\n",
            "Num timesteps: 134300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.48\n",
            "Num timesteps: 134320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.50\n",
            "Num timesteps: 134340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.50\n",
            "Num timesteps: 134360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.50\n",
            "Num timesteps: 134380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.50\n",
            "Num timesteps: 134400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.50\n",
            "Num timesteps: 134420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.50\n",
            "Num timesteps: 134440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.50\n",
            "Num timesteps: 134460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.53\n",
            "Num timesteps: 134480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.53\n",
            "Num timesteps: 134500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.53\n",
            "Num timesteps: 134520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.53\n",
            "Num timesteps: 134540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.53\n",
            "Num timesteps: 134560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.53\n",
            "Num timesteps: 134580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.51\n",
            "Num timesteps: 134600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.51\n",
            "Num timesteps: 134620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.51\n",
            "Num timesteps: 134640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.51\n",
            "Num timesteps: 134660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.51\n",
            "Num timesteps: 134680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.51\n",
            "Num timesteps: 134700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.51\n",
            "Num timesteps: 134720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.54\n",
            "Num timesteps: 134740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.54\n",
            "Num timesteps: 134760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.54\n",
            "Num timesteps: 134780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.54\n",
            "Num timesteps: 134800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.54\n",
            "Num timesteps: 134820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.54\n",
            "Num timesteps: 134840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.54\n",
            "Num timesteps: 134860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 134880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 134900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 134920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 134940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 134960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 134980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 135000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.75\n",
            "Num timesteps: 135020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.75\n",
            "Num timesteps: 135040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.75\n",
            "Num timesteps: 135060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.75\n",
            "Num timesteps: 135080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.75\n",
            "Num timesteps: 135100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.75\n",
            "Num timesteps: 135120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 135140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 135160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 135180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 135200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 135220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 135240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.77\n",
            "Num timesteps: 135260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.90\n",
            "Num timesteps: 135280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.90\n",
            "Num timesteps: 135300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.90\n",
            "Num timesteps: 135320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.90\n",
            "Num timesteps: 135340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.90\n",
            "Num timesteps: 135360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.90\n",
            "Num timesteps: 135380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.86\n",
            "Num timesteps: 135400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.86\n",
            "Num timesteps: 135420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.86\n",
            "Num timesteps: 135440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.86\n",
            "Num timesteps: 135460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.86\n",
            "Num timesteps: 135480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.86\n",
            "Num timesteps: 135500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.86\n",
            "Num timesteps: 135520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.94\n",
            "Num timesteps: 135540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.94\n",
            "Num timesteps: 135560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.94\n",
            "Num timesteps: 135580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.94\n",
            "Num timesteps: 135600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.94\n",
            "Num timesteps: 135620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.94\n",
            "Num timesteps: 135640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.94\n",
            "Num timesteps: 135660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.09\n",
            "Num timesteps: 135680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.09\n",
            "Num timesteps: 135700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.09\n",
            "Num timesteps: 135720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.09\n",
            "Num timesteps: 135740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.09\n",
            "Num timesteps: 135760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.09\n",
            "Num timesteps: 135780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.23\n",
            "Num timesteps: 135800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.23\n",
            "Num timesteps: 135820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.23\n",
            "Num timesteps: 135840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.23\n",
            "Num timesteps: 135860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.23\n",
            "Num timesteps: 135880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.23\n",
            "Num timesteps: 135900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.23\n",
            "Num timesteps: 135920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.37\n",
            "Num timesteps: 135940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.37\n",
            "Num timesteps: 135960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.37\n",
            "Num timesteps: 135980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.37\n",
            "Num timesteps: 136000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.37\n",
            "Num timesteps: 136020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.37\n",
            "Num timesteps: 136040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.28\n",
            "Num timesteps: 136060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.28\n",
            "Num timesteps: 136080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.28\n",
            "Num timesteps: 136100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.28\n",
            "Num timesteps: 136120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.28\n",
            "Num timesteps: 136140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.28\n",
            "Num timesteps: 136160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.28\n",
            "Num timesteps: 136180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.49\n",
            "Num timesteps: 136200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.49\n",
            "Num timesteps: 136220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.49\n",
            "Num timesteps: 136240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.49\n",
            "Num timesteps: 136260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.49\n",
            "Num timesteps: 136280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.49\n",
            "Num timesteps: 136300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.49\n",
            "Num timesteps: 136320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.63\n",
            "Num timesteps: 136340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.63\n",
            "Num timesteps: 136360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.63\n",
            "Num timesteps: 136380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.63\n",
            "Num timesteps: 136400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.63\n",
            "Num timesteps: 136420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.63\n",
            "Num timesteps: 136440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.68\n",
            "Num timesteps: 136460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.68\n",
            "Num timesteps: 136480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.68\n",
            "Num timesteps: 136500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.68\n",
            "Num timesteps: 136520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.68\n",
            "Num timesteps: 136540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.68\n",
            "Num timesteps: 136560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 136580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 136600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 136620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 136640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 136660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 136680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 136700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.58\n",
            "Num timesteps: 136720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.58\n",
            "Num timesteps: 136740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.58\n",
            "Num timesteps: 136760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.58\n",
            "Num timesteps: 136780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.58\n",
            "Num timesteps: 136800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.58\n",
            "Num timesteps: 136820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.43\n",
            "Num timesteps: 136840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.43\n",
            "Num timesteps: 136860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.43\n",
            "Num timesteps: 136880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.43\n",
            "Num timesteps: 136900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.43\n",
            "Num timesteps: 136920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.43\n",
            "Num timesteps: 136940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.43\n",
            "Num timesteps: 136960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.62\n",
            "Num timesteps: 136980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.62\n",
            "Num timesteps: 137000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.62\n",
            "Num timesteps: 137020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.62\n",
            "Num timesteps: 137040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.62\n",
            "Num timesteps: 137060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.62\n",
            "Num timesteps: 137080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.62\n",
            "Num timesteps: 137100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 137120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 137140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 137160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 137180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 137200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 137220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.65\n",
            "Num timesteps: 137240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.73\n",
            "Num timesteps: 137260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.73\n",
            "Num timesteps: 137280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.73\n",
            "Num timesteps: 137300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.73\n",
            "Num timesteps: 137320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.73\n",
            "Num timesteps: 137340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.73\n",
            "Num timesteps: 137360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.73\n",
            "Num timesteps: 137380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.91\n",
            "Num timesteps: 137400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.91\n",
            "Num timesteps: 137420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.91\n",
            "Num timesteps: 137440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.91\n",
            "Num timesteps: 137460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.91\n",
            "Num timesteps: 137480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.91\n",
            "Num timesteps: 137500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.91\n",
            "Num timesteps: 137520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.18\n",
            "Num timesteps: 137540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.18\n",
            "Num timesteps: 137560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.18\n",
            "Num timesteps: 137580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.18\n",
            "Num timesteps: 137600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.18\n",
            "Num timesteps: 137620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.18\n",
            "Num timesteps: 137640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.17\n",
            "Num timesteps: 137660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.17\n",
            "Num timesteps: 137680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.17\n",
            "Num timesteps: 137700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.17\n",
            "Num timesteps: 137720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.17\n",
            "Num timesteps: 137740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.17\n",
            "Num timesteps: 137760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.17\n",
            "Num timesteps: 137780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.28\n",
            "Num timesteps: 137800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.28\n",
            "Num timesteps: 137820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.28\n",
            "Num timesteps: 137840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.28\n",
            "Num timesteps: 137860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.28\n",
            "Num timesteps: 137880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.28\n",
            "Num timesteps: 137900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.28\n",
            "Num timesteps: 137920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.44\n",
            "Num timesteps: 137940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.44\n",
            "Num timesteps: 137960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.44\n",
            "Num timesteps: 137980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.44\n",
            "Num timesteps: 138000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.44\n",
            "Num timesteps: 138020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.44\n",
            "Num timesteps: 138040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.63\n",
            "Num timesteps: 138060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.63\n",
            "Num timesteps: 138080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.63\n",
            "Num timesteps: 138100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.63\n",
            "Num timesteps: 138120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.63\n",
            "Num timesteps: 138140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.63\n",
            "Num timesteps: 138160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.63\n",
            "Num timesteps: 138180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.75\n",
            "Num timesteps: 138200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.75\n",
            "Num timesteps: 138220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.75\n",
            "Num timesteps: 138240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.75\n",
            "Num timesteps: 138260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.75\n",
            "Num timesteps: 138280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.75\n",
            "Num timesteps: 138300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.99\n",
            "Num timesteps: 138320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.99\n",
            "Num timesteps: 138340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.99\n",
            "Num timesteps: 138360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.99\n",
            "Num timesteps: 138380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.99\n",
            "Num timesteps: 138400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.99\n",
            "Num timesteps: 138420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.99\n",
            "Num timesteps: 138440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.98\n",
            "Num timesteps: 138460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.98\n",
            "Num timesteps: 138480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.98\n",
            "Num timesteps: 138500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.98\n",
            "Num timesteps: 138520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.98\n",
            "Num timesteps: 138540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.98\n",
            "Num timesteps: 138560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.02\n",
            "Num timesteps: 138580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.02\n",
            "Num timesteps: 138600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.02\n",
            "Num timesteps: 138620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.02\n",
            "Num timesteps: 138640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.02\n",
            "Num timesteps: 138660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.02\n",
            "Num timesteps: 138680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.06\n",
            "Num timesteps: 138700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.06\n",
            "Num timesteps: 138720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.06\n",
            "Num timesteps: 138740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.06\n",
            "Num timesteps: 138760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.06\n",
            "Num timesteps: 138780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.06\n",
            "Num timesteps: 138800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.94\n",
            "Num timesteps: 138820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.94\n",
            "Num timesteps: 138840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.94\n",
            "Num timesteps: 138860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.94\n",
            "Num timesteps: 138880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.94\n",
            "Num timesteps: 138900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.94\n",
            "Num timesteps: 138920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.94\n",
            "Num timesteps: 138940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.94\n",
            "Num timesteps: 138960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.94\n",
            "Num timesteps: 138980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.94\n",
            "Num timesteps: 139000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.94\n",
            "Num timesteps: 139020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.94\n",
            "Num timesteps: 139040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.94\n",
            "Num timesteps: 139060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.07\n",
            "Num timesteps: 139080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.07\n",
            "Num timesteps: 139100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.07\n",
            "Num timesteps: 139120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.07\n",
            "Num timesteps: 139140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.07\n",
            "Num timesteps: 139160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.06\n",
            "Num timesteps: 139180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.06\n",
            "Num timesteps: 139200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.06\n",
            "Num timesteps: 139220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.06\n",
            "Num timesteps: 139240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.06\n",
            "Num timesteps: 139260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.06\n",
            "Num timesteps: 139280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.80\n",
            "Num timesteps: 139300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.80\n",
            "Num timesteps: 139320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.80\n",
            "Num timesteps: 139340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.80\n",
            "Num timesteps: 139360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.80\n",
            "Num timesteps: 139380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.80\n",
            "Num timesteps: 139400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.76\n",
            "Num timesteps: 139420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.76\n",
            "Num timesteps: 139440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.76\n",
            "Num timesteps: 139460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.76\n",
            "Num timesteps: 139480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.76\n",
            "Num timesteps: 139500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.76\n",
            "Num timesteps: 139520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.61\n",
            "Num timesteps: 139540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.61\n",
            "Num timesteps: 139560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.61\n",
            "Num timesteps: 139580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.61\n",
            "Num timesteps: 139600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.61\n",
            "Num timesteps: 139620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.61\n",
            "Num timesteps: 139640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.61\n",
            "Num timesteps: 139660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.44\n",
            "Num timesteps: 139680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.44\n",
            "Num timesteps: 139700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.44\n",
            "Num timesteps: 139720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.44\n",
            "Num timesteps: 139740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.44\n",
            "Num timesteps: 139760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.44\n",
            "Num timesteps: 139780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.41\n",
            "Num timesteps: 139800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.41\n",
            "Num timesteps: 139820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.41\n",
            "Num timesteps: 139840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.41\n",
            "Num timesteps: 139860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.41\n",
            "Num timesteps: 139880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.41\n",
            "Num timesteps: 139900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.41\n",
            "Num timesteps: 139920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.30\n",
            "Num timesteps: 139940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.30\n",
            "Num timesteps: 139960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.30\n",
            "Num timesteps: 139980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.30\n",
            "Num timesteps: 140000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.30\n",
            "Num timesteps: 140020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.30\n",
            "Num timesteps: 140040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.30\n",
            "Num timesteps: 140060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.36\n",
            "Num timesteps: 140080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.36\n",
            "Num timesteps: 140100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.36\n",
            "Num timesteps: 140120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.36\n",
            "Num timesteps: 140140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.36\n",
            "Num timesteps: 140160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.36\n",
            "Num timesteps: 140180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.01\n",
            "Num timesteps: 140200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.01\n",
            "Num timesteps: 140220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.01\n",
            "Num timesteps: 140240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.01\n",
            "Num timesteps: 140260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.01\n",
            "Num timesteps: 140280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.01\n",
            "Num timesteps: 140300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.01\n",
            "Num timesteps: 140320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.51\n",
            "Num timesteps: 140340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.51\n",
            "Num timesteps: 140360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.51\n",
            "Num timesteps: 140380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.51\n",
            "Num timesteps: 140400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.51\n",
            "Num timesteps: 140420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.51\n",
            "Num timesteps: 140440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.23\n",
            "Num timesteps: 140460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.23\n",
            "Num timesteps: 140480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.23\n",
            "Num timesteps: 140500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.23\n",
            "Num timesteps: 140520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.23\n",
            "Num timesteps: 140540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.23\n",
            "Num timesteps: 140560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.61\n",
            "Num timesteps: 140580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.61\n",
            "Num timesteps: 140600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.61\n",
            "Num timesteps: 140620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.61\n",
            "Num timesteps: 140640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.61\n",
            "Num timesteps: 140660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.61\n",
            "Num timesteps: 140680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.61\n",
            "Num timesteps: 140700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.54\n",
            "Num timesteps: 140720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.54\n",
            "Num timesteps: 140740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.54\n",
            "Num timesteps: 140760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.54\n",
            "Num timesteps: 140780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.54\n",
            "Num timesteps: 140800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.54\n",
            "Num timesteps: 140820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.54\n",
            "Num timesteps: 140840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.11\n",
            "Num timesteps: 140860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.11\n",
            "Num timesteps: 140880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.11\n",
            "Num timesteps: 140900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.11\n",
            "Num timesteps: 140920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.11\n",
            "Num timesteps: 140940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 150.11\n",
            "Num timesteps: 140960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.85\n",
            "Num timesteps: 140980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.85\n",
            "Num timesteps: 141000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.85\n",
            "Num timesteps: 141020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.85\n",
            "Num timesteps: 141040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.85\n",
            "Num timesteps: 141060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.85\n",
            "Num timesteps: 141080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.43\n",
            "Num timesteps: 141100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.43\n",
            "Num timesteps: 141120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.43\n",
            "Num timesteps: 141140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.43\n",
            "Num timesteps: 141160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.43\n",
            "Num timesteps: 141180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.43\n",
            "Num timesteps: 141200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.43\n",
            "Num timesteps: 141220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.88\n",
            "Num timesteps: 141240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.88\n",
            "Num timesteps: 141260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.51\n",
            "Num timesteps: 141280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.51\n",
            "Num timesteps: 141300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.51\n",
            "Num timesteps: 141320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.51\n",
            "Num timesteps: 141340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.51\n",
            "Num timesteps: 141360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.51\n",
            "Num timesteps: 141380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.51\n",
            "Num timesteps: 141400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.24\n",
            "Num timesteps: 141420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.24\n",
            "Num timesteps: 141440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.24\n",
            "Num timesteps: 141460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.24\n",
            "Num timesteps: 141480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.24\n",
            "Num timesteps: 141500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.24\n",
            "Num timesteps: 141520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.88\n",
            "Num timesteps: 141540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.88\n",
            "Num timesteps: 141560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.88\n",
            "Num timesteps: 141580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.88\n",
            "Num timesteps: 141600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.88\n",
            "Num timesteps: 141620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.88\n",
            "Num timesteps: 141640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.25\n",
            "Num timesteps: 141660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.25\n",
            "Num timesteps: 141680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.25\n",
            "Num timesteps: 141700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.25\n",
            "Num timesteps: 141720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.25\n",
            "Num timesteps: 141740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.25\n",
            "Num timesteps: 141760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.70\n",
            "Num timesteps: 141780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.70\n",
            "Num timesteps: 141800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.70\n",
            "Num timesteps: 141820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.70\n",
            "Num timesteps: 141840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.70\n",
            "Num timesteps: 141860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.70\n",
            "Num timesteps: 141880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.97\n",
            "Num timesteps: 141900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.97\n",
            "Num timesteps: 141920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.97\n",
            "Num timesteps: 141940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.97\n",
            "Num timesteps: 141960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.97\n",
            "Num timesteps: 141980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.97\n",
            "Num timesteps: 142000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.97\n",
            "Num timesteps: 142020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.46\n",
            "Num timesteps: 142040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.46\n",
            "Num timesteps: 142060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.46\n",
            "Num timesteps: 142080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.46\n",
            "Num timesteps: 142100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.46\n",
            "Num timesteps: 142120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.46\n",
            "Num timesteps: 142140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.91\n",
            "Num timesteps: 142160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.91\n",
            "Num timesteps: 142180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.91\n",
            "Num timesteps: 142200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.91\n",
            "Num timesteps: 142220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.91\n",
            "Num timesteps: 142240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.91\n",
            "Num timesteps: 142260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.91\n",
            "Num timesteps: 142280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.57\n",
            "Num timesteps: 142300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.57\n",
            "Num timesteps: 142320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.57\n",
            "Num timesteps: 142340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.57\n",
            "Num timesteps: 142360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.57\n",
            "Num timesteps: 142380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.57\n",
            "Num timesteps: 142400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.57\n",
            "Num timesteps: 142420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.17\n",
            "Num timesteps: 142440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.17\n",
            "Num timesteps: 142460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.17\n",
            "Num timesteps: 142480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.17\n",
            "Num timesteps: 142500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.17\n",
            "Num timesteps: 142520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.17\n",
            "Num timesteps: 142540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.17\n",
            "Num timesteps: 142560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.17\n",
            "Num timesteps: 142580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.98\n",
            "Num timesteps: 142600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.98\n",
            "Num timesteps: 142620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.98\n",
            "Num timesteps: 142640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.98\n",
            "Num timesteps: 142660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.98\n",
            "Num timesteps: 142680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.98\n",
            "Num timesteps: 142700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.98\n",
            "Num timesteps: 142720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.74\n",
            "Num timesteps: 142740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.74\n",
            "Num timesteps: 142760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.74\n",
            "Num timesteps: 142780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.74\n",
            "Num timesteps: 142800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.74\n",
            "Num timesteps: 142820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.74\n",
            "Num timesteps: 142840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.74\n",
            "Num timesteps: 142860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.74\n",
            "Num timesteps: 142880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.11\n",
            "Num timesteps: 142900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.11\n",
            "Num timesteps: 142920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.11\n",
            "Num timesteps: 142940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.11\n",
            "Num timesteps: 142960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.11\n",
            "Num timesteps: 142980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.11\n",
            "Num timesteps: 143000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.11\n",
            "Num timesteps: 143020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.84\n",
            "Num timesteps: 143040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.84\n",
            "Num timesteps: 143060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.84\n",
            "Num timesteps: 143080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.84\n",
            "Num timesteps: 143100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.84\n",
            "Num timesteps: 143120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.84\n",
            "Num timesteps: 143140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.84\n",
            "Num timesteps: 143160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.19\n",
            "Num timesteps: 143180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.19\n",
            "Num timesteps: 143200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.19\n",
            "Num timesteps: 143220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.19\n",
            "Num timesteps: 143240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.19\n",
            "Num timesteps: 143260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.19\n",
            "Num timesteps: 143280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.19\n",
            "Num timesteps: 143300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.19\n",
            "Num timesteps: 143320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.19\n",
            "Num timesteps: 143340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.00\n",
            "Num timesteps: 143360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.00\n",
            "Num timesteps: 143380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.00\n",
            "Num timesteps: 143400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.00\n",
            "Num timesteps: 143420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.00\n",
            "Num timesteps: 143440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.00\n",
            "Num timesteps: 143460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.00\n",
            "Num timesteps: 143480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.48\n",
            "Num timesteps: 143500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.48\n",
            "Num timesteps: 143520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.48\n",
            "Num timesteps: 143540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.48\n",
            "Num timesteps: 143560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.48\n",
            "Num timesteps: 143580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.48\n",
            "Num timesteps: 143600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.48\n",
            "Num timesteps: 143620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.48\n",
            "Num timesteps: 143640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.48\n",
            "Num timesteps: 143660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.56\n",
            "Num timesteps: 143680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.56\n",
            "Num timesteps: 143700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.56\n",
            "Num timesteps: 143720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.56\n",
            "Num timesteps: 143740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.56\n",
            "Num timesteps: 143760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.56\n",
            "Num timesteps: 143780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.56\n",
            "Num timesteps: 143800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.56\n",
            "Num timesteps: 143820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.56\n",
            "Num timesteps: 143840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.56\n",
            "Num timesteps: 143860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.55\n",
            "Num timesteps: 143880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.55\n",
            "Num timesteps: 143900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.55\n",
            "Num timesteps: 143920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.55\n",
            "Num timesteps: 143940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.55\n",
            "Num timesteps: 143960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.55\n",
            "Num timesteps: 143980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.55\n",
            "Num timesteps: 144000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.55\n",
            "Num timesteps: 144020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.55\n",
            "Num timesteps: 144040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.55\n",
            "Num timesteps: 144060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.55\n",
            "Num timesteps: 144080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.55\n",
            "Num timesteps: 144100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.89\n",
            "Num timesteps: 144120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.89\n",
            "Num timesteps: 144140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.89\n",
            "Num timesteps: 144160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.89\n",
            "Num timesteps: 144180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.89\n",
            "Num timesteps: 144200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.89\n",
            "Num timesteps: 144220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.89\n",
            "Num timesteps: 144240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.89\n",
            "Num timesteps: 144260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.89\n",
            "Num timesteps: 144280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.89\n",
            "Num timesteps: 144300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.89\n",
            "Num timesteps: 144320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.82\n",
            "Num timesteps: 144340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.82\n",
            "Num timesteps: 144360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.82\n",
            "Num timesteps: 144380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.82\n",
            "Num timesteps: 144400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.82\n",
            "Num timesteps: 144420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.82\n",
            "Num timesteps: 144440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.82\n",
            "Num timesteps: 144460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.82\n",
            "Num timesteps: 144480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.82\n",
            "Num timesteps: 144500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.82\n",
            "Num timesteps: 144520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 140.82\n",
            "Num timesteps: 144540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.43\n",
            "Num timesteps: 144820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 144840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 144860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 144880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 144900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 144920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 144940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 144960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 144980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 145000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 145020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 145040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 145060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 145080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 145100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 145120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 142.54\n",
            "Num timesteps: 145140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.08\n",
            "Num timesteps: 145160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.08\n",
            "Num timesteps: 145180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.08\n",
            "Num timesteps: 145200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.08\n",
            "Num timesteps: 145220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.08\n",
            "Num timesteps: 145240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.08\n",
            "Num timesteps: 145260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.08\n",
            "Num timesteps: 145280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.08\n",
            "Num timesteps: 145300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.07\n",
            "Num timesteps: 145320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.07\n",
            "Num timesteps: 145340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.07\n",
            "Num timesteps: 145360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.07\n",
            "Num timesteps: 145380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.07\n",
            "Num timesteps: 145400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.07\n",
            "Num timesteps: 145420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.07\n",
            "Num timesteps: 145440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.07\n",
            "Num timesteps: 145460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.07\n",
            "Num timesteps: 145480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.10\n",
            "Num timesteps: 145500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.10\n",
            "Num timesteps: 145520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.10\n",
            "Num timesteps: 145540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.10\n",
            "Num timesteps: 145560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.10\n",
            "Num timesteps: 145580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.10\n",
            "Num timesteps: 145600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.10\n",
            "Num timesteps: 145620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.10\n",
            "Num timesteps: 145640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.10\n",
            "Num timesteps: 145660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.10\n",
            "Num timesteps: 145680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.11\n",
            "Num timesteps: 145700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.11\n",
            "Num timesteps: 145720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.11\n",
            "Num timesteps: 145740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.11\n",
            "Num timesteps: 145760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.11\n",
            "Num timesteps: 145780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.11\n",
            "Num timesteps: 145800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.11\n",
            "Num timesteps: 145820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.11\n",
            "Num timesteps: 145840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.11\n",
            "Num timesteps: 145860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.11\n",
            "Num timesteps: 145880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.35\n",
            "Num timesteps: 145900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.35\n",
            "Num timesteps: 145920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.35\n",
            "Num timesteps: 145940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.35\n",
            "Num timesteps: 145960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.35\n",
            "Num timesteps: 145980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.35\n",
            "Num timesteps: 146000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.35\n",
            "Num timesteps: 146020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.35\n",
            "Num timesteps: 146040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.47\n",
            "Num timesteps: 146060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.47\n",
            "Num timesteps: 146080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.47\n",
            "Num timesteps: 146100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.47\n",
            "Num timesteps: 146120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.47\n",
            "Num timesteps: 146140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.47\n",
            "Num timesteps: 146160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.47\n",
            "Num timesteps: 146180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.47\n",
            "Num timesteps: 146200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.47\n",
            "Num timesteps: 146220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.47\n",
            "Num timesteps: 146240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.75\n",
            "Num timesteps: 146260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.75\n",
            "Num timesteps: 146280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.75\n",
            "Num timesteps: 146300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.75\n",
            "Num timesteps: 146320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.75\n",
            "Num timesteps: 146340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.75\n",
            "Num timesteps: 146360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.75\n",
            "Num timesteps: 146380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.75\n",
            "Num timesteps: 146400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 144.75\n",
            "Num timesteps: 146420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.05\n",
            "Num timesteps: 146700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.30\n",
            "Num timesteps: 146720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.30\n",
            "Num timesteps: 146740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.30\n",
            "Num timesteps: 146760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.30\n",
            "Num timesteps: 146780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.30\n",
            "Num timesteps: 146800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.30\n",
            "Num timesteps: 146820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.30\n",
            "Num timesteps: 146840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.30\n",
            "Num timesteps: 146860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.30\n",
            "Num timesteps: 146880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.30\n",
            "Num timesteps: 146900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.30\n",
            "Num timesteps: 146920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.30\n",
            "Num timesteps: 146940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 146.30\n",
            "Num timesteps: 146960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.15\n",
            "Num timesteps: 146980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.15\n",
            "Num timesteps: 147000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.15\n",
            "Num timesteps: 147020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.15\n",
            "Num timesteps: 147040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.15\n",
            "Num timesteps: 147060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.15\n",
            "Num timesteps: 147080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.15\n",
            "Num timesteps: 147100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.15\n",
            "Num timesteps: 147120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.15\n",
            "Num timesteps: 147140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.15\n",
            "Num timesteps: 147160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.79\n",
            "Num timesteps: 147440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.58\n",
            "Num timesteps: 147460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.58\n",
            "Num timesteps: 147480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.58\n",
            "Num timesteps: 147500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.58\n",
            "Num timesteps: 147520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.58\n",
            "Num timesteps: 147540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.58\n",
            "Num timesteps: 147560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.58\n",
            "Num timesteps: 147580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.58\n",
            "Num timesteps: 147600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.58\n",
            "Num timesteps: 147620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.64\n",
            "Num timesteps: 147640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.64\n",
            "Num timesteps: 147660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.64\n",
            "Num timesteps: 147680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.64\n",
            "Num timesteps: 147700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.64\n",
            "Num timesteps: 147720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.64\n",
            "Num timesteps: 147740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.64\n",
            "Num timesteps: 147760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.64\n",
            "Num timesteps: 147780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.64\n",
            "Num timesteps: 147800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.64\n",
            "Num timesteps: 147820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.64\n",
            "Num timesteps: 147840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.64\n",
            "Num timesteps: 147860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 148.64\n",
            "Num timesteps: 147880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.74\n",
            "Num timesteps: 147900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.74\n",
            "Num timesteps: 147920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.74\n",
            "Num timesteps: 147940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.74\n",
            "Num timesteps: 147960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.74\n",
            "Num timesteps: 147980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.74\n",
            "Num timesteps: 148000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.74\n",
            "Num timesteps: 148020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.55\n",
            "Num timesteps: 148040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.55\n",
            "Num timesteps: 148060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.55\n",
            "Num timesteps: 148080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.55\n",
            "Num timesteps: 148100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.55\n",
            "Num timesteps: 148120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.55\n",
            "Num timesteps: 148140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.55\n",
            "Num timesteps: 148160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.55\n",
            "Num timesteps: 148180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.55\n",
            "Num timesteps: 148200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.55\n",
            "Num timesteps: 148220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.55\n",
            "Num timesteps: 148240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.95\n",
            "Num timesteps: 148680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.93\n",
            "Num timesteps: 148700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.93\n",
            "Num timesteps: 148720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.93\n",
            "Num timesteps: 148740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.93\n",
            "Num timesteps: 148760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.93\n",
            "Num timesteps: 148780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.93\n",
            "Num timesteps: 148800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.93\n",
            "Num timesteps: 148820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.93\n",
            "Num timesteps: 148840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.93\n",
            "Num timesteps: 148860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 152.93\n",
            "Num timesteps: 148880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.55\n",
            "Num timesteps: 148900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.55\n",
            "Num timesteps: 148920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.55\n",
            "Num timesteps: 148940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.55\n",
            "Num timesteps: 148960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.55\n",
            "Num timesteps: 148980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.55\n",
            "Num timesteps: 149000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.55\n",
            "Num timesteps: 149020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.55\n",
            "Num timesteps: 149040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.55\n",
            "Num timesteps: 149060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.84\n",
            "Num timesteps: 149080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.84\n",
            "Num timesteps: 149100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.84\n",
            "Num timesteps: 149120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.84\n",
            "Num timesteps: 149140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.84\n",
            "Num timesteps: 149160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.84\n",
            "Num timesteps: 149180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.84\n",
            "Num timesteps: 149200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 153.84\n",
            "Num timesteps: 149220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.18\n",
            "Num timesteps: 149240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.18\n",
            "Num timesteps: 149260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.18\n",
            "Num timesteps: 149280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.18\n",
            "Num timesteps: 149300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.18\n",
            "Num timesteps: 149320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.18\n",
            "Num timesteps: 149340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.18\n",
            "Num timesteps: 149360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.18\n",
            "Num timesteps: 149380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.18\n",
            "Num timesteps: 149400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.75\n",
            "Num timesteps: 149780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.24\n",
            "Num timesteps: 149800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.24\n",
            "Num timesteps: 149820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.24\n",
            "Num timesteps: 149840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.24\n",
            "Num timesteps: 149860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.24\n",
            "Num timesteps: 149880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.24\n",
            "Num timesteps: 149900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.24\n",
            "Num timesteps: 149920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.24\n",
            "Num timesteps: 149940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.24\n",
            "Num timesteps: 149960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.24\n",
            "Num timesteps: 149980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.95\n",
            "Num timesteps: 150000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.95\n",
            "Num timesteps: 150020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.95\n",
            "Num timesteps: 150040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.95\n",
            "Num timesteps: 150060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.95\n",
            "Num timesteps: 150080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.95\n",
            "Num timesteps: 150100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.95\n",
            "Num timesteps: 150120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.95\n",
            "Num timesteps: 150140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.95\n",
            "Num timesteps: 150160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.95\n",
            "Num timesteps: 150180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.95\n",
            "Num timesteps: 150200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 158.79\n",
            "Num timesteps: 150220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 158.79\n",
            "Num timesteps: 150240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 158.79\n",
            "Num timesteps: 150260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 158.79\n",
            "Num timesteps: 150280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 158.79\n",
            "Num timesteps: 150300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 158.79\n",
            "Num timesteps: 150320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 158.79\n",
            "Num timesteps: 150340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 158.79\n",
            "Num timesteps: 150360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 158.79\n",
            "Num timesteps: 150380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 159.33\n",
            "Num timesteps: 150680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.92\n",
            "Num timesteps: 150700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.92\n",
            "Num timesteps: 150720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.92\n",
            "Num timesteps: 150740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.92\n",
            "Num timesteps: 150760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.92\n",
            "Num timesteps: 150780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.92\n",
            "Num timesteps: 150800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.92\n",
            "Num timesteps: 150820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.92\n",
            "Num timesteps: 150840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.92\n",
            "Num timesteps: 150860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.92\n",
            "Num timesteps: 150880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.92\n",
            "Num timesteps: 150900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.92\n",
            "Num timesteps: 150920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 150940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 150960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 150980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 151000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 151020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 151040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 151060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 151080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 151100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 151120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 151140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 151160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 151180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 151200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 151220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.16\n",
            "Num timesteps: 151240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 163.88\n",
            "Num timesteps: 151640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 166.41\n",
            "Num timesteps: 151660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 166.41\n",
            "Num timesteps: 151680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 166.41\n",
            "Num timesteps: 151700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 166.41\n",
            "Num timesteps: 151720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 166.41\n",
            "Num timesteps: 151740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 166.41\n",
            "Num timesteps: 151760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 166.41\n",
            "Num timesteps: 151780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 166.41\n",
            "Num timesteps: 151800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 166.41\n",
            "Num timesteps: 151820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 166.41\n",
            "Num timesteps: 151840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 166.41\n",
            "Num timesteps: 151860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.45\n",
            "Num timesteps: 151880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.45\n",
            "Num timesteps: 151900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.45\n",
            "Num timesteps: 151920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.45\n",
            "Num timesteps: 151940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.45\n",
            "Num timesteps: 151960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.45\n",
            "Num timesteps: 151980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.45\n",
            "Num timesteps: 152000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.45\n",
            "Num timesteps: 152020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.45\n",
            "Num timesteps: 152040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.45\n",
            "Num timesteps: 152060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.94\n",
            "Num timesteps: 152080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.94\n",
            "Num timesteps: 152100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.94\n",
            "Num timesteps: 152120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.94\n",
            "Num timesteps: 152140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.94\n",
            "Num timesteps: 152160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.94\n",
            "Num timesteps: 152180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.94\n",
            "Num timesteps: 152200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.94\n",
            "Num timesteps: 152220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.94\n",
            "Num timesteps: 152240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.62\n",
            "Num timesteps: 152260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.62\n",
            "Num timesteps: 152280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.62\n",
            "Num timesteps: 152300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.62\n",
            "Num timesteps: 152320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.62\n",
            "Num timesteps: 152340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.62\n",
            "Num timesteps: 152360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.62\n",
            "Num timesteps: 152380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.62\n",
            "Num timesteps: 152400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.62\n",
            "Num timesteps: 152420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.62\n",
            "Num timesteps: 152440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.16\n",
            "Num timesteps: 152460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.16\n",
            "Num timesteps: 152480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.16\n",
            "Num timesteps: 152500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.16\n",
            "Num timesteps: 152520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.16\n",
            "Num timesteps: 152540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.16\n",
            "Num timesteps: 152560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.16\n",
            "Num timesteps: 152580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.16\n",
            "Num timesteps: 152600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.37\n",
            "Num timesteps: 152620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.37\n",
            "Num timesteps: 152640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.37\n",
            "Num timesteps: 152660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.37\n",
            "Num timesteps: 152680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.37\n",
            "Num timesteps: 152700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.37\n",
            "Num timesteps: 152720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.37\n",
            "Num timesteps: 152740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.37\n",
            "Num timesteps: 152760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.80\n",
            "Num timesteps: 152780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.80\n",
            "Num timesteps: 152800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.80\n",
            "Num timesteps: 152820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.80\n",
            "Num timesteps: 152840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.80\n",
            "Num timesteps: 152860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.80\n",
            "Num timesteps: 152880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.80\n",
            "Num timesteps: 152900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.80\n",
            "Num timesteps: 152920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.09\n",
            "Num timesteps: 152940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.09\n",
            "Num timesteps: 152960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.09\n",
            "Num timesteps: 152980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.09\n",
            "Num timesteps: 153000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.09\n",
            "Num timesteps: 153020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.09\n",
            "Num timesteps: 153040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.09\n",
            "Num timesteps: 153060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.09\n",
            "Num timesteps: 153080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.09\n",
            "Num timesteps: 153100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.67\n",
            "Num timesteps: 153120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.67\n",
            "Num timesteps: 153140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.67\n",
            "Num timesteps: 153160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.67\n",
            "Num timesteps: 153180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.67\n",
            "Num timesteps: 153200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.67\n",
            "Num timesteps: 153220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.67\n",
            "Num timesteps: 153240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.67\n",
            "Num timesteps: 153260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.80\n",
            "Num timesteps: 153280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.80\n",
            "Num timesteps: 153300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.80\n",
            "Num timesteps: 153320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.80\n",
            "Num timesteps: 153340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.80\n",
            "Num timesteps: 153360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.80\n",
            "Num timesteps: 153380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.80\n",
            "Num timesteps: 153400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.80\n",
            "Num timesteps: 153420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.80\n",
            "Num timesteps: 153440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 171.14\n",
            "Num timesteps: 153460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 171.14\n",
            "Num timesteps: 153480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 171.14\n",
            "Num timesteps: 153500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 171.14\n",
            "Num timesteps: 153520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 171.14\n",
            "Num timesteps: 153540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 171.14\n",
            "Num timesteps: 153560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 171.14\n",
            "Num timesteps: 153580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 171.14\n",
            "Num timesteps: 153600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 171.14\n",
            "Num timesteps: 153620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 171.14\n",
            "Num timesteps: 153640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 171.14\n",
            "Num timesteps: 153660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.10\n",
            "Num timesteps: 153680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.10\n",
            "Num timesteps: 153700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.10\n",
            "Num timesteps: 153720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.10\n",
            "Num timesteps: 153740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.10\n",
            "Num timesteps: 153760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.10\n",
            "Num timesteps: 153780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.10\n",
            "Num timesteps: 153800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.10\n",
            "Num timesteps: 153820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.10\n",
            "Num timesteps: 153840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.10\n",
            "Num timesteps: 153860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.97\n",
            "Num timesteps: 153880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.97\n",
            "Num timesteps: 153900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.97\n",
            "Num timesteps: 153920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.97\n",
            "Num timesteps: 153940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.97\n",
            "Num timesteps: 153960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.97\n",
            "Num timesteps: 153980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.97\n",
            "Num timesteps: 154000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.97\n",
            "Num timesteps: 154020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.97\n",
            "Num timesteps: 154040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 173.49\n",
            "Num timesteps: 154060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 173.49\n",
            "Num timesteps: 154080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 173.49\n",
            "Num timesteps: 154100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 173.49\n",
            "Num timesteps: 154120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 173.49\n",
            "Num timesteps: 154140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 173.49\n",
            "Num timesteps: 154160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 173.49\n",
            "Num timesteps: 154180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 173.49\n",
            "Num timesteps: 154200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 173.49\n",
            "Num timesteps: 154220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 173.49\n",
            "Num timesteps: 154240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 173.49\n",
            "Num timesteps: 154260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.29\n",
            "Num timesteps: 154280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.29\n",
            "Num timesteps: 154300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.29\n",
            "Num timesteps: 154320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.29\n",
            "Num timesteps: 154340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.29\n",
            "Num timesteps: 154360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.29\n",
            "Num timesteps: 154380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.29\n",
            "Num timesteps: 154400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.29\n",
            "Num timesteps: 154420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.29\n",
            "Num timesteps: 154440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.29\n",
            "Num timesteps: 154460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.29\n",
            "Num timesteps: 154480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 175.18\n",
            "Num timesteps: 154500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 175.18\n",
            "Num timesteps: 154520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 175.18\n",
            "Num timesteps: 154540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 175.18\n",
            "Num timesteps: 154560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 175.18\n",
            "Num timesteps: 154580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 175.18\n",
            "Num timesteps: 154600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 175.18\n",
            "Num timesteps: 154620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 175.18\n",
            "Num timesteps: 154640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 175.18\n",
            "Num timesteps: 154660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 175.18\n",
            "Num timesteps: 154680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 175.18\n",
            "Num timesteps: 154700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 175.18\n",
            "Num timesteps: 154720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.31\n",
            "Num timesteps: 154740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.31\n",
            "Num timesteps: 154760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.31\n",
            "Num timesteps: 154780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.31\n",
            "Num timesteps: 154800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.31\n",
            "Num timesteps: 154820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.31\n",
            "Num timesteps: 154840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.31\n",
            "Num timesteps: 154860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.31\n",
            "Num timesteps: 154880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.31\n",
            "Num timesteps: 154900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.31\n",
            "Num timesteps: 154920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.31\n",
            "Num timesteps: 154940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.31\n",
            "Num timesteps: 154960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.25\n",
            "Num timesteps: 154980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.25\n",
            "Num timesteps: 155000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.25\n",
            "Num timesteps: 155020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.25\n",
            "Num timesteps: 155040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.25\n",
            "Num timesteps: 155060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.25\n",
            "Num timesteps: 155080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.25\n",
            "Num timesteps: 155100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.25\n",
            "Num timesteps: 155120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.25\n",
            "Num timesteps: 155140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.73\n",
            "Num timesteps: 155540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.14\n",
            "Num timesteps: 155560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.14\n",
            "Num timesteps: 155580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.14\n",
            "Num timesteps: 155600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.14\n",
            "Num timesteps: 155620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.14\n",
            "Num timesteps: 155640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.14\n",
            "Num timesteps: 155660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.14\n",
            "Num timesteps: 155680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.14\n",
            "Num timesteps: 155700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.61\n",
            "Num timesteps: 155720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.61\n",
            "Num timesteps: 155740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.61\n",
            "Num timesteps: 155760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.61\n",
            "Num timesteps: 155780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.61\n",
            "Num timesteps: 155800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.61\n",
            "Num timesteps: 155820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.61\n",
            "Num timesteps: 155840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.61\n",
            "Num timesteps: 155860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.61\n",
            "Num timesteps: 155880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.98\n",
            "Num timesteps: 155900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.98\n",
            "Num timesteps: 155920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.98\n",
            "Num timesteps: 155940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.98\n",
            "Num timesteps: 155960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.98\n",
            "Num timesteps: 155980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.98\n",
            "Num timesteps: 156000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.98\n",
            "Num timesteps: 156020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.98\n",
            "Num timesteps: 156040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.98\n",
            "Num timesteps: 156060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.98\n",
            "Num timesteps: 156080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.98\n",
            "Num timesteps: 156100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 181.88\n",
            "Num timesteps: 156120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 181.88\n",
            "Num timesteps: 156140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 181.88\n",
            "Num timesteps: 156160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 181.88\n",
            "Num timesteps: 156180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 181.88\n",
            "Num timesteps: 156200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 181.88\n",
            "Num timesteps: 156220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 181.88\n",
            "Num timesteps: 156240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 181.88\n",
            "Num timesteps: 156260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 181.88\n",
            "Num timesteps: 156280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 181.88\n",
            "Num timesteps: 156300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 181.88\n",
            "Num timesteps: 156320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.72\n",
            "Num timesteps: 156340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.72\n",
            "Num timesteps: 156360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.72\n",
            "Num timesteps: 156380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.72\n",
            "Num timesteps: 156400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.72\n",
            "Num timesteps: 156420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.72\n",
            "Num timesteps: 156440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.72\n",
            "Num timesteps: 156460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.72\n",
            "Num timesteps: 156480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.72\n",
            "Num timesteps: 156500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.72\n",
            "Num timesteps: 156520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 182.72\n",
            "Num timesteps: 156540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.74\n",
            "Num timesteps: 156560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.74\n",
            "Num timesteps: 156580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.74\n",
            "Num timesteps: 156600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.74\n",
            "Num timesteps: 156620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.74\n",
            "Num timesteps: 156640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.74\n",
            "Num timesteps: 156660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.74\n",
            "Num timesteps: 156680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.74\n",
            "Num timesteps: 156700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.74\n",
            "Num timesteps: 156720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.74\n",
            "Num timesteps: 156740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 183.74\n",
            "Num timesteps: 156760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 156780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 156800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 156820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 156840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 156860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 156880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 156900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 156920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 156940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 156960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 156980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 157000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 157020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 157040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 157060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 157080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.49\n",
            "Num timesteps: 157100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.58\n",
            "Num timesteps: 157120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.58\n",
            "Num timesteps: 157140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.58\n",
            "Num timesteps: 157160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.58\n",
            "Num timesteps: 157180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.58\n",
            "Num timesteps: 157200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.58\n",
            "Num timesteps: 157220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.58\n",
            "Num timesteps: 157240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.58\n",
            "Num timesteps: 157260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.58\n",
            "Num timesteps: 157280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.58\n",
            "Num timesteps: 157300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 187.33\n",
            "Num timesteps: 157320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.40\n",
            "Num timesteps: 157340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.40\n",
            "Num timesteps: 157360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.40\n",
            "Num timesteps: 157380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.40\n",
            "Num timesteps: 157400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.40\n",
            "Num timesteps: 157420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.40\n",
            "Num timesteps: 157440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.40\n",
            "Num timesteps: 157460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.65\n",
            "Num timesteps: 157760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.47\n",
            "Num timesteps: 157780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.47\n",
            "Num timesteps: 157800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.47\n",
            "Num timesteps: 157820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.47\n",
            "Num timesteps: 157840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.47\n",
            "Num timesteps: 157860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.47\n",
            "Num timesteps: 157880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.47\n",
            "Num timesteps: 157900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.47\n",
            "Num timesteps: 157920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.47\n",
            "Num timesteps: 157940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.47\n",
            "Num timesteps: 157960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.47\n",
            "Num timesteps: 157980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.47\n",
            "Num timesteps: 158000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.47\n",
            "Num timesteps: 158020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 189.58\n",
            "Num timesteps: 158040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 189.58\n",
            "Num timesteps: 158060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 189.58\n",
            "Num timesteps: 158080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 189.58\n",
            "Num timesteps: 158100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 189.58\n",
            "Num timesteps: 158120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 189.45\n",
            "Num timesteps: 158140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 188.52\n",
            "Num timesteps: 158160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 186.36\n",
            "Num timesteps: 158180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 185.15\n",
            "Num timesteps: 158200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 184.15\n",
            "Num timesteps: 158220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 181.72\n",
            "Num timesteps: 158240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 181.72\n",
            "Num timesteps: 158260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.80\n",
            "Num timesteps: 158280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 180.80\n",
            "Num timesteps: 158300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 179.86\n",
            "Num timesteps: 158320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 178.77\n",
            "Num timesteps: 158340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 177.76\n",
            "Num timesteps: 158360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.59\n",
            "Num timesteps: 158380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 176.59\n",
            "Num timesteps: 158400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 175.59\n",
            "Num timesteps: 158420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 174.58\n",
            "Num timesteps: 158440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.30\n",
            "Num timesteps: 158460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.30\n",
            "Num timesteps: 158480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 172.30\n",
            "Num timesteps: 158500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 171.16\n",
            "Num timesteps: 158520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 171.16\n",
            "Num timesteps: 158540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 170.12\n",
            "Num timesteps: 158560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.27\n",
            "Num timesteps: 158580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 169.27\n",
            "Num timesteps: 158600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 168.39\n",
            "Num timesteps: 158620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 167.37\n",
            "Num timesteps: 158640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 166.28\n",
            "Num timesteps: 158660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 165.10\n",
            "Num timesteps: 158680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 164.01\n",
            "Num timesteps: 158700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 162.82\n",
            "Num timesteps: 158720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 161.56\n",
            "Num timesteps: 158740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.19\n",
            "Num timesteps: 158760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 160.19\n",
            "Num timesteps: 158780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 157.63\n",
            "Num timesteps: 158800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 156.34\n",
            "Num timesteps: 158820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 154.70\n",
            "Num timesteps: 158840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 151.77\n",
            "Num timesteps: 158860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 149.94\n",
            "Num timesteps: 158880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 147.62\n",
            "Num timesteps: 158900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 145.89\n",
            "Num timesteps: 158920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 143.74\n",
            "Num timesteps: 158940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 141.25\n",
            "Num timesteps: 158960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 138.27\n",
            "Num timesteps: 158980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 134.95\n",
            "Num timesteps: 159000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 133.38\n",
            "Num timesteps: 159020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 133.38\n",
            "Num timesteps: 159040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 130.09\n",
            "Num timesteps: 159060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 128.18\n",
            "Num timesteps: 159080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 126.54\n",
            "Num timesteps: 159100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 123.99\n",
            "Num timesteps: 159120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 121.58\n",
            "Num timesteps: 159140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 119.76\n",
            "Num timesteps: 159160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 117.20\n",
            "Num timesteps: 159180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 113.16\n",
            "Num timesteps: 159200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 113.16\n",
            "Num timesteps: 159220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 111.92\n",
            "Num timesteps: 159240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 111.92\n",
            "Num timesteps: 159260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 105.98\n",
            "Num timesteps: 159280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 104.02\n",
            "Num timesteps: 159300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 102.43\n",
            "Num timesteps: 159320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 101.07\n",
            "Num timesteps: 159340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 99.33\n",
            "Num timesteps: 159360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 95.82\n",
            "Num timesteps: 159380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 95.82\n",
            "Num timesteps: 159400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 94.10\n",
            "Num timesteps: 159420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 92.21\n",
            "Num timesteps: 159440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 90.63\n",
            "Num timesteps: 159460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 90.63\n",
            "Num timesteps: 159480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 87.99\n",
            "Num timesteps: 159500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 87.99\n",
            "Num timesteps: 159520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 85.86\n",
            "Num timesteps: 159540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 79.16\n",
            "Num timesteps: 159560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 77.00\n",
            "Num timesteps: 159580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 77.00\n",
            "Num timesteps: 159600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 75.46\n",
            "Num timesteps: 159620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 75.46\n",
            "Num timesteps: 159640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.92\n",
            "Num timesteps: 159660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.92\n",
            "Num timesteps: 159680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.92\n",
            "Num timesteps: 159700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.92\n",
            "Num timesteps: 159720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.92\n",
            "Num timesteps: 159740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.92\n",
            "Num timesteps: 159760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.92\n",
            "Num timesteps: 159780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.57\n",
            "Num timesteps: 159800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.57\n",
            "Num timesteps: 159820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.36\n",
            "Num timesteps: 159840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.36\n",
            "Num timesteps: 159860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.36\n",
            "Num timesteps: 159880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.20\n",
            "Num timesteps: 159900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.20\n",
            "Num timesteps: 159920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.20\n",
            "Num timesteps: 159940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.20\n",
            "Num timesteps: 159960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.20\n",
            "Num timesteps: 159980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.20\n",
            "Num timesteps: 160000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.20\n",
            "Num timesteps: 160020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.02\n",
            "Num timesteps: 160040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.02\n",
            "Num timesteps: 160060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.02\n",
            "Num timesteps: 160080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.02\n",
            "Num timesteps: 160100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.02\n",
            "Num timesteps: 160120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.02\n",
            "Num timesteps: 160140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 71.02\n",
            "Num timesteps: 160160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.59\n",
            "Num timesteps: 160180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.59\n",
            "Num timesteps: 160200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 69.33\n",
            "Num timesteps: 160220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 69.33\n",
            "Num timesteps: 160240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 69.33\n",
            "Num timesteps: 160260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 69.33\n",
            "Num timesteps: 160280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 69.33\n",
            "Num timesteps: 160300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 69.33\n",
            "Num timesteps: 160320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 69.33\n",
            "Num timesteps: 160340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 69.02\n",
            "Num timesteps: 160360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 69.02\n",
            "Num timesteps: 160380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.36\n",
            "Num timesteps: 160660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.87\n",
            "Num timesteps: 160680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.87\n",
            "Num timesteps: 160700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.87\n",
            "Num timesteps: 160720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.87\n",
            "Num timesteps: 160740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.87\n",
            "Num timesteps: 160760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.87\n",
            "Num timesteps: 160780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.87\n",
            "Num timesteps: 160800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.87\n",
            "Num timesteps: 160820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.87\n",
            "Num timesteps: 160840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 67.87\n",
            "Num timesteps: 160860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.16\n",
            "Num timesteps: 160880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.16\n",
            "Num timesteps: 160900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.16\n",
            "Num timesteps: 160920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.16\n",
            "Num timesteps: 160940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.16\n",
            "Num timesteps: 160960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.16\n",
            "Num timesteps: 160980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.16\n",
            "Num timesteps: 161000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.16\n",
            "Num timesteps: 161020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.16\n",
            "Num timesteps: 161040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.16\n",
            "Num timesteps: 161060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.16\n",
            "Num timesteps: 161080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.16\n",
            "Num timesteps: 161100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.16\n",
            "Num timesteps: 161120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 68.70\n",
            "Num timesteps: 161480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161780\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161800\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161820\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161840\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161860\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161880\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161900\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161920\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161940\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161960\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 70.02\n",
            "Num timesteps: 161980\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.57\n",
            "Num timesteps: 162000\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.57\n",
            "Num timesteps: 162020\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.57\n",
            "Num timesteps: 162040\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.57\n",
            "Num timesteps: 162060\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.57\n",
            "Num timesteps: 162080\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.57\n",
            "Num timesteps: 162100\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.57\n",
            "Num timesteps: 162120\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.57\n",
            "Num timesteps: 162140\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.57\n",
            "Num timesteps: 162160\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.57\n",
            "Num timesteps: 162180\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.57\n",
            "Num timesteps: 162200\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.57\n",
            "Num timesteps: 162220\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.57\n",
            "Num timesteps: 162240\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.84\n",
            "Num timesteps: 162260\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.84\n",
            "Num timesteps: 162280\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.84\n",
            "Num timesteps: 162300\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.84\n",
            "Num timesteps: 162320\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.84\n",
            "Num timesteps: 162340\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.84\n",
            "Num timesteps: 162360\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.84\n",
            "Num timesteps: 162380\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.84\n",
            "Num timesteps: 162400\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.84\n",
            "Num timesteps: 162420\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.84\n",
            "Num timesteps: 162440\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.84\n",
            "Num timesteps: 162460\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 72.84\n",
            "Num timesteps: 162480\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162500\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162520\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162540\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162560\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162580\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162600\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162620\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162640\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162660\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162680\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162700\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162720\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162740\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n",
            "Num timesteps: 162760\n",
            "Best mean reward: 290.23 - Last mean reward per episode: 73.29\n"
          ]
        }
      ],
      "source": [
        "model = RecurrentPPO('MlpLstmPolicy', env,\n",
        "            verbose=0,\n",
        "            learning_rate =0.002455056236483535,\n",
        "            n_steps = 520,\n",
        "            batch_size = 512,\n",
        "            gamma= 0.8897700488124874,\n",
        "            gae_lambda=0.8757069936152605)\n",
        "model.learn(total_timesteps=500000, callback = callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og8n-8MDE2II"
      },
      "outputs": [],
      "source": [
        "def plot_training_results(training_steps_per_second, reward_averages, reward_std):\n",
        "    \"\"\"\n",
        "    Utility function for plotting the results of training\n",
        "\n",
        "    :param training_steps_per_second: List[double]\n",
        "    :param reward_averages: List[double]\n",
        "    :param reward_std: List[double]\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(9, 4))\n",
        "    plt.subplots_adjust(wspace=0.5)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.errorbar(\n",
        "        PROCESSES_TO_TEST,\n",
        "        reward_averages,\n",
        "        yerr=reward_std,\n",
        "        capsize=2,\n",
        "        c=\"k\",\n",
        "        marker=\"o\",\n",
        "    )\n",
        "    plt.xlabel(\"Processes\")\n",
        "    plt.ylabel(\"Average return\")\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.bar(range(len(PROCESSES_TO_TEST)), training_steps_per_second)\n",
        "    plt.xticks(range(len(PROCESSES_TO_TEST)), PROCESSES_TO_TEST)\n",
        "    plt.xlabel(\"Processes\")\n",
        "    plt.ylabel(\"Training steps per second\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "5aFtakvPEhEX",
        "outputId": "1e9727bf-8b18-475a-bac6-0eec603a7327"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 900x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "training_steps_per_second = [TRAIN_STEPS / t for t in training_times]\n",
        "\n",
        "plot_training_results(training_steps_per_second, reward_averages, reward_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlRX8g9JEgzc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-hDF_jLAIQr"
      },
      "outputs": [],
      "source": [
        "# The different number of processes that will be used\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEb8CaVVAIGf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rku2VX09vwC",
        "outputId": "bc211b37-4569-4df3-f95a-06144d082ae8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 512, but because the `RolloutBuffer` is of size `n_steps * n_envs = 20`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 20\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=5 and n_envs=4)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = PPO('MlpPolicy', env,\n",
        "            verbose=0,\n",
        "            learning_rate =0.002455056236483535,\n",
        "            n_steps = 5,  #520\n",
        "            batch_size = 512,\n",
        "            gamma= 0.8897700488124874,\n",
        "            gae_lambda=0.8757069936152605)\n",
        "model.learn(total_timesteps=100000)\n",
        "model.save('ppo_stock_trading')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMNu6FE-_CLI"
      },
      "outputs": [],
      "source": [
        "# Parameter sellect code\n",
        "# import gymnasium as gym\n",
        "# import optuna\n",
        "# import pandas as pd\n",
        "# from stable_baselines3 import PPO\n",
        "# from stable_baselines3.common.env_util import make_vec_env\n",
        "# from stable_baselines3.common.callbacks import EvalCallback\n",
        "# from stable_baselines3.common.monitor import Monitor\n",
        "# from gym import spaces\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "# def optimize_ppo(trial):\n",
        "#     # 하이퍼파라미터를 Optuna의 trial 객체를 통해 샘플링\n",
        "#     learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
        "#     n_steps = trial.suggest_int('n_steps', 128, 2048)\n",
        "#     batch_size = trial.suggest_categorical('batch_size', [64, 128, 256, 512, 1024])\n",
        "#     gamma = trial.suggest_uniform('gamma', 0.8, 0.9999)\n",
        "#     gae_lambda = trial.suggest_uniform('gae_lambda', 0.8, 0.99)\n",
        "\n",
        "#     # 환경 생성\n",
        "#     # data = pd.read_csv('daily_stock_prices.csv')  # 데이터 불러오기\n",
        "\n",
        "#     train_env = make_vec_env(make_env(df, rank=0), n_envs=n_envs)\n",
        "#     eval_env = Monitor(StockPortfolioEnv(df))\n",
        "\n",
        "#     # PPO 모델 생성\n",
        "#     model = PPO(\n",
        "#         \"MlpPolicy\",\n",
        "#         train_env,\n",
        "#         learning_rate=learning_rate,\n",
        "#         n_steps=n_steps,\n",
        "#         batch_size=batch_size,\n",
        "#         gamma=gamma,\n",
        "#         gae_lambda=gae_lambda,\n",
        "#         verbose=0\n",
        "#     )\n",
        "\n",
        "    # 아래는 기존에 생성한 env임, 비교 평가를 위해서 넣음\n",
        "    #env = make_vec_env(make_env(df, rank=0), n_envs=n_envs)\n",
        "    # 평가 환경 설정\n",
        "    # eval_callback = EvalCallback(eval_env, eval_freq=500, n_eval_episodes=50, verbose=0)\n",
        "\n",
        "    # 모델 학습\n",
        "    # model.learn(total_timesteps=5000, callback=eval_callback)\n",
        "\n",
        "    # 마지막 평가에서의 평균 보상 반환\n",
        "    # mean_reward = eval_callback.last_mean_reward\n",
        "    # return mean_reward\n",
        "\n",
        "# study = optuna.create_study(direction='maximize')\n",
        "# study.optimize(optimize_ppo, n_trials=50)\n",
        "\n",
        "# print(\"Best trial:\")\n",
        "# trial = study.best_trial\n",
        "# print(f\"Value: {trial.value}\")\n",
        "# print(\"Params: \")\n",
        "# for key, value in trial.params.items():\n",
        "#     print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeH1Fjrr_CFr"
      },
      "outputs": [],
      "source": [
        "# Best trial:\n",
        "# Value: 7535583987.41942\n",
        "# Params:\n",
        "# learning_rate: 0.0024550562364583535\n",
        "# n_steps: 590\n",
        "# batch_size: 512\n",
        "# gamma: 0.8897700488124874\n",
        "# gae_lambda: 0.8757069936152605"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inOGfnb0_CAy"
      },
      "outputs": [],
      "source": [
        "# Tensorboard logging check when model learning.\n",
        "# from stable_baselines3.common.logger import configure\n",
        "\n",
        "# # 텐서보드 로거 설정\n",
        "# log_path = \"./ppo_stock_trading_logs2/\"\n",
        "# new_logger = configure(log_path, [\"stdout\", \"tensorboard\"])\n",
        "# model.set_logger(new_logger)\n",
        "\n",
        "# # 텐서보드에서 학습 로그를 확인하려면, 아래 명령어를 실행하세요.\n",
        "# # !tensorboard --logdir=./ppo_stock_trading_logs/\n",
        "\n",
        "# # 학습 시작 및 로그 확인 가능\n",
        "# model.learn(total_timesteps=10000000000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOs0gMitJMqlcF2xJUpTVL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}